{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0.0200</th>\n",
       "      <th>0.0371</th>\n",
       "      <th>0.0428</th>\n",
       "      <th>0.0207</th>\n",
       "      <th>0.0954</th>\n",
       "      <th>0.0986</th>\n",
       "      <th>0.1539</th>\n",
       "      <th>0.1601</th>\n",
       "      <th>0.3109</th>\n",
       "      <th>0.2111</th>\n",
       "      <th>...</th>\n",
       "      <th>0.0027</th>\n",
       "      <th>0.0065</th>\n",
       "      <th>0.0159</th>\n",
       "      <th>0.0072</th>\n",
       "      <th>0.0167</th>\n",
       "      <th>0.0180</th>\n",
       "      <th>0.0084</th>\n",
       "      <th>0.0090</th>\n",
       "      <th>0.0032</th>\n",
       "      <th>R</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0453</td>\n",
       "      <td>0.0523</td>\n",
       "      <td>0.0843</td>\n",
       "      <td>0.0689</td>\n",
       "      <td>0.1183</td>\n",
       "      <td>0.2583</td>\n",
       "      <td>0.2156</td>\n",
       "      <td>0.3481</td>\n",
       "      <td>0.3337</td>\n",
       "      <td>0.2872</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0084</td>\n",
       "      <td>0.0089</td>\n",
       "      <td>0.0048</td>\n",
       "      <td>0.0094</td>\n",
       "      <td>0.0191</td>\n",
       "      <td>0.0140</td>\n",
       "      <td>0.0049</td>\n",
       "      <td>0.0052</td>\n",
       "      <td>0.0044</td>\n",
       "      <td>R</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0262</td>\n",
       "      <td>0.0582</td>\n",
       "      <td>0.1099</td>\n",
       "      <td>0.1083</td>\n",
       "      <td>0.0974</td>\n",
       "      <td>0.2280</td>\n",
       "      <td>0.2431</td>\n",
       "      <td>0.3771</td>\n",
       "      <td>0.5598</td>\n",
       "      <td>0.6194</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0232</td>\n",
       "      <td>0.0166</td>\n",
       "      <td>0.0095</td>\n",
       "      <td>0.0180</td>\n",
       "      <td>0.0244</td>\n",
       "      <td>0.0316</td>\n",
       "      <td>0.0164</td>\n",
       "      <td>0.0095</td>\n",
       "      <td>0.0078</td>\n",
       "      <td>R</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0100</td>\n",
       "      <td>0.0171</td>\n",
       "      <td>0.0623</td>\n",
       "      <td>0.0205</td>\n",
       "      <td>0.0205</td>\n",
       "      <td>0.0368</td>\n",
       "      <td>0.1098</td>\n",
       "      <td>0.1276</td>\n",
       "      <td>0.0598</td>\n",
       "      <td>0.1264</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0121</td>\n",
       "      <td>0.0036</td>\n",
       "      <td>0.0150</td>\n",
       "      <td>0.0085</td>\n",
       "      <td>0.0073</td>\n",
       "      <td>0.0050</td>\n",
       "      <td>0.0044</td>\n",
       "      <td>0.0040</td>\n",
       "      <td>0.0117</td>\n",
       "      <td>R</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0762</td>\n",
       "      <td>0.0666</td>\n",
       "      <td>0.0481</td>\n",
       "      <td>0.0394</td>\n",
       "      <td>0.0590</td>\n",
       "      <td>0.0649</td>\n",
       "      <td>0.1209</td>\n",
       "      <td>0.2467</td>\n",
       "      <td>0.3564</td>\n",
       "      <td>0.4459</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0031</td>\n",
       "      <td>0.0054</td>\n",
       "      <td>0.0105</td>\n",
       "      <td>0.0110</td>\n",
       "      <td>0.0015</td>\n",
       "      <td>0.0072</td>\n",
       "      <td>0.0048</td>\n",
       "      <td>0.0107</td>\n",
       "      <td>0.0094</td>\n",
       "      <td>R</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0286</td>\n",
       "      <td>0.0453</td>\n",
       "      <td>0.0277</td>\n",
       "      <td>0.0174</td>\n",
       "      <td>0.0384</td>\n",
       "      <td>0.0990</td>\n",
       "      <td>0.1201</td>\n",
       "      <td>0.1833</td>\n",
       "      <td>0.2105</td>\n",
       "      <td>0.3039</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0045</td>\n",
       "      <td>0.0014</td>\n",
       "      <td>0.0038</td>\n",
       "      <td>0.0013</td>\n",
       "      <td>0.0089</td>\n",
       "      <td>0.0057</td>\n",
       "      <td>0.0027</td>\n",
       "      <td>0.0051</td>\n",
       "      <td>0.0062</td>\n",
       "      <td>R</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 61 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   0.0200  0.0371  0.0428  0.0207  0.0954  0.0986  0.1539  0.1601  0.3109  \\\n",
       "0  0.0453  0.0523  0.0843  0.0689  0.1183  0.2583  0.2156  0.3481  0.3337   \n",
       "1  0.0262  0.0582  0.1099  0.1083  0.0974  0.2280  0.2431  0.3771  0.5598   \n",
       "2  0.0100  0.0171  0.0623  0.0205  0.0205  0.0368  0.1098  0.1276  0.0598   \n",
       "3  0.0762  0.0666  0.0481  0.0394  0.0590  0.0649  0.1209  0.2467  0.3564   \n",
       "4  0.0286  0.0453  0.0277  0.0174  0.0384  0.0990  0.1201  0.1833  0.2105   \n",
       "\n",
       "   0.2111  ...  0.0027  0.0065  0.0159  0.0072  0.0167  0.0180  0.0084  \\\n",
       "0  0.2872  ...  0.0084  0.0089  0.0048  0.0094  0.0191  0.0140  0.0049   \n",
       "1  0.6194  ...  0.0232  0.0166  0.0095  0.0180  0.0244  0.0316  0.0164   \n",
       "2  0.1264  ...  0.0121  0.0036  0.0150  0.0085  0.0073  0.0050  0.0044   \n",
       "3  0.4459  ...  0.0031  0.0054  0.0105  0.0110  0.0015  0.0072  0.0048   \n",
       "4  0.3039  ...  0.0045  0.0014  0.0038  0.0013  0.0089  0.0057  0.0027   \n",
       "\n",
       "   0.0090  0.0032  R  \n",
       "0  0.0052  0.0044  R  \n",
       "1  0.0095  0.0078  R  \n",
       "2  0.0040  0.0117  R  \n",
       "3  0.0107  0.0094  R  \n",
       "4  0.0051  0.0062  R  \n",
       "\n",
       "[5 rows x 61 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df=pd.read_csv('C:/Users/AndyJazz/Desktop/Dataset/rock and mine/sonar.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(207, 60)\n",
      "(165, 60)\n",
      "(165, 2)\n",
      "(42, 60)\n",
      "n_dim 60\n",
      "epoch : 0 - cost: 103.32463 - MSE: 9034.164275562493 -Train Accuracy: 0.45454547\n",
      "epoch : 1 - cost: 6.721039 - MSE: 78.18070096524556 -Train Accuracy: 0.54545456\n",
      "epoch : 2 - cost: 3.988475 - MSE: 25.31353443984 -Train Accuracy: 0.45454547\n",
      "epoch : 3 - cost: 4.691158 - MSE: 26.77249827965999 -Train Accuracy: 0.54545456\n",
      "epoch : 4 - cost: 0.9964619 - MSE: 1.0500558293686806 -Train Accuracy: 0.45454547\n",
      "epoch : 5 - cost: 0.707001 - MSE: 0.5202279349218102 -Train Accuracy: 0.45454547\n",
      "epoch : 6 - cost: 0.69856685 - MSE: 0.5545522509878935 -Train Accuracy: 0.46060607\n",
      "epoch : 7 - cost: 0.6925538 - MSE: 0.6096594651487288 -Train Accuracy: 0.4848485\n",
      "epoch : 8 - cost: 0.68857014 - MSE: 0.6567355811369769 -Train Accuracy: 0.57575756\n",
      "epoch : 9 - cost: 0.68592465 - MSE: 0.6951080030274781 -Train Accuracy: 0.58787876\n",
      "epoch : 10 - cost: 0.6841259 - MSE: 0.7278851505528114 -Train Accuracy: 0.55151516\n",
      "epoch : 11 - cost: 0.68289304 - MSE: 0.7517520898897511 -Train Accuracy: 0.54545456\n",
      "epoch : 12 - cost: 0.6819771 - MSE: 0.7650826794717873 -Train Accuracy: 0.53939396\n",
      "epoch : 13 - cost: 0.6811959 - MSE: 0.774934555093286 -Train Accuracy: 0.54545456\n",
      "epoch : 14 - cost: 0.6803926 - MSE: 0.7734520396529136 -Train Accuracy: 0.54545456\n",
      "epoch : 15 - cost: 0.6796003 - MSE: 0.7660446686602185 -Train Accuracy: 0.53939396\n",
      "epoch : 16 - cost: 0.6787698 - MSE: 0.7579801294482735 -Train Accuracy: 0.54545456\n",
      "epoch : 17 - cost: 0.67783874 - MSE: 0.7478035112452145 -Train Accuracy: 0.55151516\n",
      "epoch : 18 - cost: 0.6767763 - MSE: 0.7383163667978184 -Train Accuracy: 0.55151516\n",
      "epoch : 19 - cost: 0.6755901 - MSE: 0.7306099425038862 -Train Accuracy: 0.56363636\n",
      "epoch : 20 - cost: 0.67437524 - MSE: 0.7256576178942663 -Train Accuracy: 0.56969696\n",
      "epoch : 21 - cost: 0.6730871 - MSE: 0.7220699641844694 -Train Accuracy: 0.56363636\n",
      "epoch : 22 - cost: 0.6717432 - MSE: 0.7191794895272204 -Train Accuracy: 0.56363636\n",
      "epoch : 23 - cost: 0.6702737 - MSE: 0.7126760965812651 -Train Accuracy: 0.56969696\n",
      "epoch : 24 - cost: 0.6687198 - MSE: 0.7119238790871137 -Train Accuracy: 0.57575756\n",
      "epoch : 25 - cost: 0.6670826 - MSE: 0.7123949775068065 -Train Accuracy: 0.6\n",
      "epoch : 26 - cost: 0.66537815 - MSE: 0.7092289738972356 -Train Accuracy: 0.6121212\n",
      "epoch : 27 - cost: 0.6635536 - MSE: 0.7082056452271952 -Train Accuracy: 0.630303\n",
      "epoch : 28 - cost: 0.66162467 - MSE: 0.7082761749686334 -Train Accuracy: 0.6363636\n",
      "epoch : 29 - cost: 0.6596071 - MSE: 0.7019005809358153 -Train Accuracy: 0.6606061\n",
      "epoch : 30 - cost: 0.6574258 - MSE: 0.6981581296067721 -Train Accuracy: 0.6666667\n",
      "epoch : 31 - cost: 0.6551473 - MSE: 0.6967486314673486 -Train Accuracy: 0.6787879\n",
      "epoch : 32 - cost: 0.65279174 - MSE: 0.6997435876688097 -Train Accuracy: 0.6848485\n",
      "epoch : 33 - cost: 0.65027916 - MSE: 0.6945098717998318 -Train Accuracy: 0.6909091\n",
      "epoch : 34 - cost: 0.64766717 - MSE: 0.6967677367190168 -Train Accuracy: 0.6909091\n",
      "epoch : 35 - cost: 0.64493823 - MSE: 0.6975335371374075 -Train Accuracy: 0.6848485\n",
      "epoch : 36 - cost: 0.64205223 - MSE: 0.7110093644718513 -Train Accuracy: 0.6969697\n",
      "epoch : 37 - cost: 0.6391059 - MSE: 0.7045073743238939 -Train Accuracy: 0.6909091\n",
      "epoch : 38 - cost: 0.63595194 - MSE: 0.7188232502545043 -Train Accuracy: 0.6969697\n",
      "epoch : 39 - cost: 0.63271487 - MSE: 0.7011488750018154 -Train Accuracy: 0.6848485\n",
      "epoch : 40 - cost: 0.6293766 - MSE: 0.7336954928207424 -Train Accuracy: 0.7030303\n",
      "epoch : 41 - cost: 0.62586486 - MSE: 0.7016615712195438 -Train Accuracy: 0.6969697\n",
      "epoch : 42 - cost: 0.62229186 - MSE: 0.7475877691328454 -Train Accuracy: 0.7090909\n",
      "epoch : 43 - cost: 0.6190533 - MSE: 0.678437360816639 -Train Accuracy: 0.6787879\n",
      "epoch : 44 - cost: 0.6166513 - MSE: 0.8199838131158179 -Train Accuracy: 0.6787879\n",
      "epoch : 45 - cost: 0.6217014 - MSE: 0.5663395952814438 -Train Accuracy: 0.6424242\n",
      "epoch : 46 - cost: 0.66345763 - MSE: 1.3152249844476258 -Train Accuracy: 0.56363636\n",
      "epoch : 47 - cost: 0.78716886 - MSE: 0.560346025601026 -Train Accuracy: 0.45454547\n",
      "epoch : 48 - cost: 0.6794152 - MSE: 1.077884203610865 -Train Accuracy: 0.55757576\n",
      "epoch : 49 - cost: 0.6795138 - MSE: 0.3643633132672865 -Train Accuracy: 0.55151516\n",
      "epoch : 50 - cost: 0.6312908 - MSE: 0.4216065555981623 -Train Accuracy: 0.6969697\n",
      "epoch : 51 - cost: 0.6265402 - MSE: 0.790262846297773 -Train Accuracy: 0.6424242\n",
      "epoch : 52 - cost: 0.64759886 - MSE: 0.4112252957823222 -Train Accuracy: 0.630303\n",
      "epoch : 53 - cost: 0.67385787 - MSE: 1.2775203271771178 -Train Accuracy: 0.56363636\n",
      "epoch : 54 - cost: 0.7086145 - MSE: 0.43403039261360765 -Train Accuracy: 0.4909091\n",
      "epoch : 55 - cost: 0.61504066 - MSE: 0.6063411808975355 -Train Accuracy: 0.6727273\n",
      "epoch : 56 - cost: 0.60866284 - MSE: 0.4727472277048448 -Train Accuracy: 0.7151515\n",
      "epoch : 57 - cost: 0.6131199 - MSE: 0.8348478969079355 -Train Accuracy: 0.6727273\n",
      "epoch : 58 - cost: 0.64177585 - MSE: 0.4233641215626543 -Train Accuracy: 0.630303\n",
      "epoch : 59 - cost: 0.70733005 - MSE: 1.5124290934151692 -Train Accuracy: 0.55757576\n",
      "epoch : 60 - cost: 0.75274813 - MSE: 0.515304623815058 -Train Accuracy: 0.45454547\n",
      "epoch : 61 - cost: 0.6100872 - MSE: 0.4783927770368374 -Train Accuracy: 0.7090909\n",
      "epoch : 62 - cost: 0.5953322 - MSE: 0.5844531297211726 -Train Accuracy: 0.7030303\n",
      "epoch : 63 - cost: 0.58547425 - MSE: 0.5287919197268283 -Train Accuracy: 0.74545455\n",
      "epoch : 64 - cost: 0.578658 - MSE: 0.6895043358794559 -Train Accuracy: 0.6969697\n",
      "epoch : 65 - cost: 0.5805383 - MSE: 0.4785271757180948 -Train Accuracy: 0.74545455\n",
      "epoch : 66 - cost: 0.6212619 - MSE: 1.132660151684319 -Train Accuracy: 0.6242424\n",
      "epoch : 67 - cost: 0.775001 - MSE: 0.6193601829263172 -Train Accuracy: 0.46060607\n",
      "epoch : 68 - cost: 0.64819777 - MSE: 1.003490656841178 -Train Accuracy: 0.58787876\n",
      "epoch : 69 - cost: 0.67824054 - MSE: 0.38624096839627214 -Train Accuracy: 0.5212121\n",
      "epoch : 70 - cost: 0.629912 - MSE: 0.3588807506446539 -Train Accuracy: 0.73333335\n",
      "epoch : 71 - cost: 0.57558113 - MSE: 0.48386461762317934 -Train Accuracy: 0.6969697\n",
      "epoch : 72 - cost: 0.5546971 - MSE: 0.5326893798221767 -Train Accuracy: 0.73333335\n",
      "epoch : 73 - cost: 0.54123384 - MSE: 0.6075594435652354 -Train Accuracy: 0.72727275\n",
      "epoch : 74 - cost: 0.53052825 - MSE: 0.5694543736633199 -Train Accuracy: 0.75151515\n",
      "epoch : 75 - cost: 0.5412233 - MSE: 0.9307054852645157 -Train Accuracy: 0.6909091\n",
      "epoch : 76 - cost: 0.78305495 - MSE: 0.6927489378691591 -Train Accuracy: 0.4848485\n",
      "epoch : 77 - cost: 0.9453418 - MSE: 2.275841164160088 -Train Accuracy: 0.55151516\n",
      "epoch : 78 - cost: 0.7200901 - MSE: 0.49164807703954866 -Train Accuracy: 0.45454547\n",
      "epoch : 79 - cost: 0.6796479 - MSE: 0.40544805483854873 -Train Accuracy: 0.47272727\n",
      "epoch : 80 - cost: 0.6710074 - MSE: 0.3996476469385619 -Train Accuracy: 0.5090909\n",
      "epoch : 81 - cost: 0.657953 - MSE: 0.39491739500121714 -Train Accuracy: 0.6606061\n",
      "epoch : 82 - cost: 0.6385132 - MSE: 0.44904099947762577 -Train Accuracy: 0.6969697\n",
      "epoch : 83 - cost: 0.6214996 - MSE: 0.6308055859839131 -Train Accuracy: 0.6727273\n",
      "epoch : 84 - cost: 0.61140406 - MSE: 0.5548257552817775 -Train Accuracy: 0.7030303\n",
      "epoch : 85 - cost: 0.619088 - MSE: 0.9271551392096623 -Train Accuracy: 0.6606061\n",
      "epoch : 86 - cost: 0.7181144 - MSE: 0.5178917275079025 -Train Accuracy: 0.47878787\n",
      "epoch : 87 - cost: 0.67609084 - MSE: 0.9419124469378344 -Train Accuracy: 0.58181816\n",
      "epoch : 88 - cost: 0.6774137 - MSE: 0.4137941638803455 -Train Accuracy: 0.47272727\n",
      "epoch : 89 - cost: 0.65320784 - MSE: 0.3525400958282271 -Train Accuracy: 0.73333335\n",
      "epoch : 90 - cost: 0.6393723 - MSE: 0.3414064524740132 -Train Accuracy: 0.7151515\n",
      "epoch : 91 - cost: 0.61984533 - MSE: 0.32368575347408557 -Train Accuracy: 0.75757575\n",
      "epoch : 92 - cost: 0.5926399 - MSE: 0.4100845331870222 -Train Accuracy: 0.7090909\n",
      "epoch : 93 - cost: 0.5825302 - MSE: 0.37893389932048216 -Train Accuracy: 0.73333335\n",
      "epoch : 94 - cost: 0.641739 - MSE: 0.8693524452726794 -Train Accuracy: 0.6484848\n",
      "epoch : 95 - cost: 0.89681584 - MSE: 0.857096287042319 -Train Accuracy: 0.45454547\n",
      "epoch : 96 - cost: 0.6621317 - MSE: 0.35459663247827455 -Train Accuracy: 0.54545456\n",
      "epoch : 97 - cost: 0.64502937 - MSE: 0.33376724285061005 -Train Accuracy: 0.58181816\n",
      "epoch : 98 - cost: 0.61865866 - MSE: 0.3507964837043386 -Train Accuracy: 0.6545454\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch : 99 - cost: 0.5942408 - MSE: 0.2912528356511375 -Train Accuracy: 0.76969695\n",
      "epoch : 100 - cost: 0.58617884 - MSE: 0.4551200746517936 -Train Accuracy: 0.6848485\n",
      "epoch : 101 - cost: 0.6614858 - MSE: 0.39229525721047376 -Train Accuracy: 0.56969696\n",
      "epoch : 102 - cost: 0.70066595 - MSE: 0.746520210209817 -Train Accuracy: 0.56969696\n",
      "epoch : 103 - cost: 0.7452979 - MSE: 0.5604844576657984 -Train Accuracy: 0.45454547\n",
      "epoch : 104 - cost: 0.63966465 - MSE: 0.33372493403978637 -Train Accuracy: 0.6606061\n",
      "epoch : 105 - cost: 0.6247535 - MSE: 0.326093949362695 -Train Accuracy: 0.76969695\n",
      "epoch : 106 - cost: 0.6115675 - MSE: 0.3336831542366414 -Train Accuracy: 0.76363635\n",
      "epoch : 107 - cost: 0.5977992 - MSE: 0.3694496506235385 -Train Accuracy: 0.75757575\n",
      "epoch : 108 - cost: 0.58500725 - MSE: 0.4244289927234605 -Train Accuracy: 0.74545455\n",
      "epoch : 109 - cost: 0.5726308 - MSE: 0.4628778576049393 -Train Accuracy: 0.75757575\n",
      "epoch : 110 - cost: 0.5592988 - MSE: 0.4928128916201407 -Train Accuracy: 0.76363635\n",
      "epoch : 111 - cost: 0.5451139 - MSE: 0.4962602420377091 -Train Accuracy: 0.76363635\n",
      "epoch : 112 - cost: 0.53132796 - MSE: 0.46309410647665655 -Train Accuracy: 0.77575755\n",
      "epoch : 113 - cost: 0.5152495 - MSE: 0.4875478685104932 -Train Accuracy: 0.75151515\n",
      "epoch : 114 - cost: 0.5549099 - MSE: 0.3745586311359597 -Train Accuracy: 0.6909091\n",
      "epoch : 115 - cost: 1.2108465 - MSE: 2.8661762757501266 -Train Accuracy: 0.55151516\n",
      "epoch : 116 - cost: 1.2186332 - MSE: 1.7047831601177283 -Train Accuracy: 0.45454547\n",
      "epoch : 117 - cost: 0.693821 - MSE: 0.494638203006958 -Train Accuracy: 0.54545456\n",
      "epoch : 118 - cost: 0.69251525 - MSE: 0.48932690862521866 -Train Accuracy: 0.54545456\n",
      "epoch : 119 - cost: 0.69156134 - MSE: 0.4851211355168513 -Train Accuracy: 0.54545456\n",
      "epoch : 120 - cost: 0.69086534 - MSE: 0.48177293483525513 -Train Accuracy: 0.54545456\n",
      "epoch : 121 - cost: 0.69035834 - MSE: 0.47909287639255826 -Train Accuracy: 0.54545456\n",
      "epoch : 122 - cost: 0.6899893 - MSE: 0.47693592905860205 -Train Accuracy: 0.54545456\n",
      "epoch : 123 - cost: 0.6897211 - MSE: 0.4751907263888925 -Train Accuracy: 0.54545456\n",
      "epoch : 124 - cost: 0.6895258 - MSE: 0.47377142326037697 -Train Accuracy: 0.54545456\n",
      "epoch : 125 - cost: 0.68938416 - MSE: 0.472611537720244 -Train Accuracy: 0.54545456\n",
      "epoch : 126 - cost: 0.6892813 - MSE: 0.4716593392220433 -Train Accuracy: 0.54545456\n",
      "epoch : 127 - cost: 0.68920654 - MSE: 0.4708743444920665 -Train Accuracy: 0.54545456\n",
      "epoch : 128 - cost: 0.68915254 - MSE: 0.47022471026875257 -Train Accuracy: 0.54545456\n",
      "epoch : 129 - cost: 0.689113 - MSE: 0.4696851992966541 -Train Accuracy: 0.54545456\n",
      "epoch : 130 - cost: 0.6890845 - MSE: 0.4692357595883586 -Train Accuracy: 0.54545456\n",
      "epoch : 131 - cost: 0.6890639 - MSE: 0.46886029680615576 -Train Accuracy: 0.54545456\n",
      "epoch : 132 - cost: 0.68904865 - MSE: 0.46854583941664063 -Train Accuracy: 0.54545456\n",
      "epoch : 133 - cost: 0.6890378 - MSE: 0.46828191364029015 -Train Accuracy: 0.54545456\n",
      "epoch : 134 - cost: 0.6890301 - MSE: 0.4680599626864157 -Train Accuracy: 0.54545456\n",
      "epoch : 135 - cost: 0.6890243 - MSE: 0.46787299741133265 -Train Accuracy: 0.54545456\n",
      "epoch : 136 - cost: 0.68902004 - MSE: 0.467715272982928 -Train Accuracy: 0.54545456\n",
      "epoch : 137 - cost: 0.6890172 - MSE: 0.4675820488382876 -Train Accuracy: 0.54545456\n",
      "epoch : 138 - cost: 0.6890149 - MSE: 0.4674693962219958 -Train Accuracy: 0.54545456\n",
      "epoch : 139 - cost: 0.6890133 - MSE: 0.46737404759689954 -Train Accuracy: 0.54545456\n",
      "epoch : 140 - cost: 0.6890122 - MSE: 0.46729327974988405 -Train Accuracy: 0.54545456\n",
      "epoch : 141 - cost: 0.68901134 - MSE: 0.4672248137967843 -Train Accuracy: 0.54545456\n",
      "epoch : 142 - cost: 0.6890109 - MSE: 0.46716673402187514 -Train Accuracy: 0.54545456\n",
      "epoch : 143 - cost: 0.6890105 - MSE: 0.4671174458782625 -Train Accuracy: 0.54545456\n",
      "epoch : 144 - cost: 0.6890101 - MSE: 0.46707559932806386 -Train Accuracy: 0.54545456\n",
      "epoch : 145 - cost: 0.6890098 - MSE: 0.46704006388606123 -Train Accuracy: 0.54545456\n",
      "epoch : 146 - cost: 0.6890097 - MSE: 0.46700986374449727 -Train Accuracy: 0.54545456\n",
      "epoch : 147 - cost: 0.6890096 - MSE: 0.4669841960853672 -Train Accuracy: 0.54545456\n",
      "epoch : 148 - cost: 0.6890095 - MSE: 0.4669623980984608 -Train Accuracy: 0.54545456\n",
      "epoch : 149 - cost: 0.68900925 - MSE: 0.4669438490565976 -Train Accuracy: 0.54545456\n",
      "epoch : 150 - cost: 0.68900937 - MSE: 0.4669280774050967 -Train Accuracy: 0.54545456\n",
      "epoch : 151 - cost: 0.68900937 - MSE: 0.4669146681611602 -Train Accuracy: 0.54545456\n",
      "epoch : 152 - cost: 0.6890093 - MSE: 0.46690325648920805 -Train Accuracy: 0.54545456\n",
      "epoch : 153 - cost: 0.6890093 - MSE: 0.46689354742078926 -Train Accuracy: 0.54545456\n",
      "epoch : 154 - cost: 0.6890092 - MSE: 0.46688528334782237 -Train Accuracy: 0.54545456\n",
      "epoch : 155 - cost: 0.68900925 - MSE: 0.466878253180016 -Train Accuracy: 0.54545456\n",
      "epoch : 156 - cost: 0.68900937 - MSE: 0.46687228663655905 -Train Accuracy: 0.54545456\n",
      "epoch : 157 - cost: 0.68900937 - MSE: 0.4668672002948966 -Train Accuracy: 0.54545456\n",
      "epoch : 158 - cost: 0.6890093 - MSE: 0.4668628702690252 -Train Accuracy: 0.54545456\n",
      "epoch : 159 - cost: 0.6890093 - MSE: 0.46685918244045765 -Train Accuracy: 0.54545456\n",
      "epoch : 160 - cost: 0.6890093 - MSE: 0.46685605142296455 -Train Accuracy: 0.54545456\n",
      "epoch : 161 - cost: 0.6890092 - MSE: 0.4668533654226102 -Train Accuracy: 0.54545456\n",
      "epoch : 162 - cost: 0.68900925 - MSE: 0.4668510889233083 -Train Accuracy: 0.54545456\n",
      "epoch : 163 - cost: 0.6890093 - MSE: 0.4668491517670021 -Train Accuracy: 0.54545456\n",
      "epoch : 164 - cost: 0.6890091 - MSE: 0.46684750696306826 -Train Accuracy: 0.54545456\n",
      "epoch : 165 - cost: 0.68900937 - MSE: 0.4668461075448141 -Train Accuracy: 0.54545456\n",
      "epoch : 166 - cost: 0.68900925 - MSE: 0.4668449167765665 -Train Accuracy: 0.54545456\n",
      "epoch : 167 - cost: 0.68900925 - MSE: 0.46684390744537074 -Train Accuracy: 0.54545456\n",
      "epoch : 168 - cost: 0.68900925 - MSE: 0.46684304418781997 -Train Accuracy: 0.54545456\n",
      "epoch : 169 - cost: 0.6890092 - MSE: 0.46684230049029585 -Train Accuracy: 0.54545456\n",
      "epoch : 170 - cost: 0.68900937 - MSE: 0.4668416756883665 -Train Accuracy: 0.54545456\n",
      "epoch : 171 - cost: 0.6890092 - MSE: 0.46684114326700116 -Train Accuracy: 0.54545456\n",
      "epoch : 172 - cost: 0.68900937 - MSE: 0.46684068691940944 -Train Accuracy: 0.54545456\n",
      "epoch : 173 - cost: 0.68900925 - MSE: 0.4668402964497337 -Train Accuracy: 0.54545456\n",
      "epoch : 174 - cost: 0.6890093 - MSE: 0.46683995281046886 -Train Accuracy: 0.54545456\n",
      "epoch : 175 - cost: 0.68900925 - MSE: 0.46683967100336415 -Train Accuracy: 0.54545456\n",
      "epoch : 176 - cost: 0.68900913 - MSE: 0.4668394360650933 -Train Accuracy: 0.54545456\n",
      "epoch : 177 - cost: 0.6890092 - MSE: 0.4668392303168611 -Train Accuracy: 0.54545456\n",
      "epoch : 178 - cost: 0.6890093 - MSE: 0.46683905920455615 -Train Accuracy: 0.54545456\n",
      "epoch : 179 - cost: 0.6890093 - MSE: 0.4668389077814403 -Train Accuracy: 0.54545456\n",
      "epoch : 180 - cost: 0.68900937 - MSE: 0.46683878964213865 -Train Accuracy: 0.54545456\n",
      "epoch : 181 - cost: 0.6890091 - MSE: 0.4668386803116974 -Train Accuracy: 0.54545456\n",
      "epoch : 182 - cost: 0.6890093 - MSE: 0.46683858931856603 -Train Accuracy: 0.54545456\n",
      "epoch : 183 - cost: 0.6890091 - MSE: 0.4668385228001169 -Train Accuracy: 0.54545456\n",
      "epoch : 184 - cost: 0.68900937 - MSE: 0.4668384528603142 -Train Accuracy: 0.54545456\n",
      "epoch : 185 - cost: 0.68900937 - MSE: 0.46683839854130466 -Train Accuracy: 0.54545456\n",
      "epoch : 186 - cost: 0.6890092 - MSE: 0.4668383435319862 -Train Accuracy: 0.54545456\n",
      "epoch : 187 - cost: 0.68900913 - MSE: 0.46683829938654015 -Train Accuracy: 0.54545456\n",
      "epoch : 188 - cost: 0.68900925 - MSE: 0.4668382674858998 -Train Accuracy: 0.54545456\n",
      "epoch : 189 - cost: 0.68900937 - MSE: 0.4668382205939527 -Train Accuracy: 0.54545456\n",
      "epoch : 190 - cost: 0.6890093 - MSE: 0.46683819070346205 -Train Accuracy: 0.54545456\n",
      "epoch : 191 - cost: 0.68900925 - MSE: 0.4668381655697013 -Train Accuracy: 0.54545456\n",
      "epoch : 192 - cost: 0.68900925 - MSE: 0.46683814451753186 -Train Accuracy: 0.54545456\n",
      "epoch : 193 - cost: 0.68900925 - MSE: 0.4668381255061685 -Train Accuracy: 0.54545456\n",
      "epoch : 194 - cost: 0.68900925 - MSE: 0.4668381234962125 -Train Accuracy: 0.54545456\n",
      "epoch : 195 - cost: 0.6890093 - MSE: 0.46683811059181207 -Train Accuracy: 0.54545456\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch : 196 - cost: 0.6890092 - MSE: 0.46683810585054986 -Train Accuracy: 0.54545456\n",
      "epoch : 197 - cost: 0.68900925 - MSE: 0.4668381133539886 -Train Accuracy: 0.54545456\n",
      "epoch : 198 - cost: 0.6890093 - MSE: 0.4668381099629709 -Train Accuracy: 0.54545456\n",
      "epoch : 199 - cost: 0.6890092 - MSE: 0.46683810112472424 -Train Accuracy: 0.54545456\n",
      "epoch : 200 - cost: 0.6890092 - MSE: 0.4668380963680431 -Train Accuracy: 0.54545456\n",
      "epoch : 201 - cost: 0.6890092 - MSE: 0.4668380916113624 -Train Accuracy: 0.54545456\n",
      "epoch : 202 - cost: 0.6890092 - MSE: 0.46683808685468253 -Train Accuracy: 0.54545456\n",
      "epoch : 203 - cost: 0.6890093 - MSE: 0.4668380820980031 -Train Accuracy: 0.54545456\n",
      "epoch : 204 - cost: 0.6890093 - MSE: 0.46683807734132426 -Train Accuracy: 0.54545456\n",
      "epoch : 205 - cost: 0.6890093 - MSE: 0.4668380725846459 -Train Accuracy: 0.54545456\n",
      "epoch : 206 - cost: 0.6890093 - MSE: 0.4668380678279684 -Train Accuracy: 0.54545456\n",
      "epoch : 207 - cost: 0.6890093 - MSE: 0.4668380630712911 -Train Accuracy: 0.54545456\n",
      "epoch : 208 - cost: 0.6890093 - MSE: 0.4668380603553963 -Train Accuracy: 0.54545456\n",
      "epoch : 209 - cost: 0.6890092 - MSE: 0.46683805763950187 -Train Accuracy: 0.54545456\n",
      "epoch : 210 - cost: 0.6890092 - MSE: 0.4668380549236081 -Train Accuracy: 0.54545456\n",
      "epoch : 211 - cost: 0.6890092 - MSE: 0.4668380522077144 -Train Accuracy: 0.54545456\n",
      "epoch : 212 - cost: 0.6890091 - MSE: 0.46683805969572906 -Train Accuracy: 0.54545456\n",
      "epoch : 213 - cost: 0.6890091 - MSE: 0.4668380671837438 -Train Accuracy: 0.54545456\n",
      "epoch : 214 - cost: 0.6890091 - MSE: 0.4668380767125408 -Train Accuracy: 0.54545456\n",
      "epoch : 215 - cost: 0.6890095 - MSE: 0.4668380862413376 -Train Accuracy: 0.54545456\n",
      "epoch : 216 - cost: 0.6890095 - MSE: 0.46683809372935314 -Train Accuracy: 0.54545456\n",
      "epoch : 217 - cost: 0.6890095 - MSE: 0.466838101217369 -Train Accuracy: 0.54545456\n",
      "epoch : 218 - cost: 0.68900925 - MSE: 0.4668381087053852 -Train Accuracy: 0.54545456\n",
      "epoch : 219 - cost: 0.68900925 - MSE: 0.46683811619340143 -Train Accuracy: 0.54545456\n",
      "epoch : 220 - cost: 0.68900925 - MSE: 0.46683812368141797 -Train Accuracy: 0.54545456\n",
      "epoch : 221 - cost: 0.6890095 - MSE: 0.4668381311694349 -Train Accuracy: 0.54545456\n",
      "epoch : 222 - cost: 0.68900925 - MSE: 0.46683812776298145 -Train Accuracy: 0.54545456\n",
      "epoch : 223 - cost: 0.68900925 - MSE: 0.4668381352509981 -Train Accuracy: 0.54545456\n",
      "epoch : 224 - cost: 0.6890095 - MSE: 0.46683814273901547 -Train Accuracy: 0.54545456\n",
      "epoch : 225 - cost: 0.68900925 - MSE: 0.4668381393325618 -Train Accuracy: 0.54545456\n",
      "epoch : 226 - cost: 0.68900925 - MSE: 0.466838146820579 -Train Accuracy: 0.54545456\n",
      "epoch : 227 - cost: 0.6890095 - MSE: 0.46683815430859615 -Train Accuracy: 0.54545456\n",
      "epoch : 228 - cost: 0.68900925 - MSE: 0.46683815090214265 -Train Accuracy: 0.54545456\n",
      "epoch : 229 - cost: 0.6890095 - MSE: 0.46683815839015985 -Train Accuracy: 0.54545456\n",
      "epoch : 230 - cost: 0.68900925 - MSE: 0.4668381549837064 -Train Accuracy: 0.54545456\n",
      "epoch : 231 - cost: 0.68900925 - MSE: 0.46683816247172366 -Train Accuracy: 0.54545456\n",
      "epoch : 232 - cost: 0.6890095 - MSE: 0.4668381699597412 -Train Accuracy: 0.54545456\n",
      "epoch : 233 - cost: 0.68900925 - MSE: 0.46683816655328736 -Train Accuracy: 0.54545456\n",
      "epoch : 234 - cost: 0.68900925 - MSE: 0.4668381740413051 -Train Accuracy: 0.54545456\n",
      "epoch : 235 - cost: 0.6890095 - MSE: 0.4668381815293228 -Train Accuracy: 0.54545456\n",
      "epoch : 236 - cost: 0.68900925 - MSE: 0.466838178122869 -Train Accuracy: 0.54545456\n",
      "epoch : 237 - cost: 0.6890095 - MSE: 0.4668381856108867 -Train Accuracy: 0.54545456\n",
      "epoch : 238 - cost: 0.68900925 - MSE: 0.46683818220443285 -Train Accuracy: 0.54545456\n",
      "epoch : 239 - cost: 0.68900925 - MSE: 0.46683818969245056 -Train Accuracy: 0.54545456\n",
      "epoch : 240 - cost: 0.6890095 - MSE: 0.46683819718046893 -Train Accuracy: 0.54545456\n",
      "epoch : 241 - cost: 0.68900925 - MSE: 0.4668381937740148 -Train Accuracy: 0.54545456\n",
      "epoch : 242 - cost: 0.68900925 - MSE: 0.46683820126203285 -Train Accuracy: 0.54545456\n",
      "epoch : 243 - cost: 0.6890095 - MSE: 0.4668382087500512 -Train Accuracy: 0.54545456\n",
      "epoch : 244 - cost: 0.68900925 - MSE: 0.46683820534359705 -Train Accuracy: 0.54545456\n",
      "epoch : 245 - cost: 0.6890095 - MSE: 0.4668382128316153 -Train Accuracy: 0.54545456\n",
      "epoch : 246 - cost: 0.68900925 - MSE: 0.46683820942516113 -Train Accuracy: 0.54545456\n",
      "epoch : 247 - cost: 0.68900925 - MSE: 0.4668382169131795 -Train Accuracy: 0.54545456\n",
      "epoch : 248 - cost: 0.6890095 - MSE: 0.46683822440119843 -Train Accuracy: 0.54545456\n",
      "epoch : 249 - cost: 0.68900925 - MSE: 0.4668382209947439 -Train Accuracy: 0.54545456\n",
      "epoch : 250 - cost: 0.68900925 - MSE: 0.46683822848276246 -Train Accuracy: 0.54545456\n",
      "epoch : 251 - cost: 0.6890095 - MSE: 0.4668382359707814 -Train Accuracy: 0.54545456\n",
      "epoch : 252 - cost: 0.68900925 - MSE: 0.4668382325643269 -Train Accuracy: 0.54545456\n",
      "epoch : 253 - cost: 0.6890095 - MSE: 0.466838240052346 -Train Accuracy: 0.54545456\n",
      "epoch : 254 - cost: 0.68900925 - MSE: 0.46683823664589125 -Train Accuracy: 0.54545456\n",
      "epoch : 255 - cost: 0.68900925 - MSE: 0.46683824413391006 -Train Accuracy: 0.54545456\n",
      "epoch : 256 - cost: 0.6890095 - MSE: 0.46683825162192943 -Train Accuracy: 0.54545456\n",
      "epoch : 257 - cost: 0.68900925 - MSE: 0.46683824821547454 -Train Accuracy: 0.54545456\n",
      "epoch : 258 - cost: 0.68900925 - MSE: 0.46683825570349397 -Train Accuracy: 0.54545456\n",
      "epoch : 259 - cost: 0.6890095 - MSE: 0.4668382631915134 -Train Accuracy: 0.54545456\n",
      "epoch : 260 - cost: 0.68900925 - MSE: 0.46683825978505855 -Train Accuracy: 0.54545456\n",
      "epoch : 261 - cost: 0.6890095 - MSE: 0.466838267273078 -Train Accuracy: 0.54545456\n",
      "epoch : 262 - cost: 0.68900925 - MSE: 0.4668382638666231 -Train Accuracy: 0.54545456\n",
      "epoch : 263 - cost: 0.68900925 - MSE: 0.46683827135464256 -Train Accuracy: 0.54545456\n",
      "epoch : 264 - cost: 0.6890095 - MSE: 0.46683827884266244 -Train Accuracy: 0.54545456\n",
      "epoch : 265 - cost: 0.68900925 - MSE: 0.4668382754362072 -Train Accuracy: 0.54545456\n",
      "epoch : 266 - cost: 0.68900925 - MSE: 0.46683828292422713 -Train Accuracy: 0.54545456\n",
      "epoch : 267 - cost: 0.6890095 - MSE: 0.4668382904122471 -Train Accuracy: 0.54545456\n",
      "epoch : 268 - cost: 0.68900925 - MSE: 0.4668382870057918 -Train Accuracy: 0.54545456\n",
      "epoch : 269 - cost: 0.6890095 - MSE: 0.4668382944938119 -Train Accuracy: 0.54545456\n",
      "epoch : 270 - cost: 0.68900925 - MSE: 0.4668382910873566 -Train Accuracy: 0.54545456\n",
      "epoch : 271 - cost: 0.68900925 - MSE: 0.4668382985753767 -Train Accuracy: 0.54545456\n",
      "epoch : 272 - cost: 0.6890095 - MSE: 0.4668383060633973 -Train Accuracy: 0.54545456\n",
      "epoch : 273 - cost: 0.68900925 - MSE: 0.46683830265694176 -Train Accuracy: 0.54545456\n",
      "epoch : 274 - cost: 0.68900925 - MSE: 0.4668383101449622 -Train Accuracy: 0.54545456\n",
      "epoch : 275 - cost: 0.6890095 - MSE: 0.46683831763298267 -Train Accuracy: 0.54545456\n",
      "epoch : 276 - cost: 0.68900925 - MSE: 0.4668383142265271 -Train Accuracy: 0.54545456\n",
      "epoch : 277 - cost: 0.6890095 - MSE: 0.46683832171454787 -Train Accuracy: 0.54545456\n",
      "epoch : 278 - cost: 0.68900925 - MSE: 0.46683831830809225 -Train Accuracy: 0.54545456\n",
      "epoch : 279 - cost: 0.68900925 - MSE: 0.46683832579611273 -Train Accuracy: 0.54545456\n",
      "epoch : 280 - cost: 0.6890095 - MSE: 0.4668383332841337 -Train Accuracy: 0.54545456\n",
      "epoch : 281 - cost: 0.68900925 - MSE: 0.4668383298776778 -Train Accuracy: 0.54545456\n",
      "epoch : 282 - cost: 0.68900925 - MSE: 0.4668383373656989 -Train Accuracy: 0.54545456\n",
      "epoch : 283 - cost: 0.6890095 - MSE: 0.46683834485372 -Train Accuracy: 0.54545456\n",
      "epoch : 284 - cost: 0.68900925 - MSE: 0.466838341447264 -Train Accuracy: 0.54545456\n",
      "epoch : 285 - cost: 0.6890095 - MSE: 0.4668383489352853 -Train Accuracy: 0.54545456\n",
      "epoch : 286 - cost: 0.68900925 - MSE: 0.4668383455288292 -Train Accuracy: 0.54545456\n",
      "epoch : 287 - cost: 0.68900925 - MSE: 0.46683835301685034 -Train Accuracy: 0.54545456\n",
      "epoch : 288 - cost: 0.6890095 - MSE: 0.46683836050487215 -Train Accuracy: 0.54545456\n",
      "epoch : 289 - cost: 0.68900925 - MSE: 0.4668383570984157 -Train Accuracy: 0.54545456\n",
      "epoch : 290 - cost: 0.68900925 - MSE: 0.4668383645864375 -Train Accuracy: 0.54545456\n",
      "epoch : 291 - cost: 0.6890095 - MSE: 0.46683837207445905 -Train Accuracy: 0.54545456\n",
      "epoch : 292 - cost: 0.68900925 - MSE: 0.46683836866800293 -Train Accuracy: 0.54545456\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch : 293 - cost: 0.6890095 - MSE: 0.4668383761560245 -Train Accuracy: 0.54545456\n",
      "epoch : 294 - cost: 0.68900925 - MSE: 0.4668383727495683 -Train Accuracy: 0.54545456\n",
      "epoch : 295 - cost: 0.68900925 - MSE: 0.4668383802375901 -Train Accuracy: 0.54545456\n",
      "epoch : 296 - cost: 0.6890095 - MSE: 0.46683838772561226 -Train Accuracy: 0.54545456\n",
      "epoch : 297 - cost: 0.68900925 - MSE: 0.4668383843191556 -Train Accuracy: 0.54545456\n",
      "epoch : 298 - cost: 0.68900925 - MSE: 0.46683839180717773 -Train Accuracy: 0.54545456\n",
      "epoch : 299 - cost: 0.6890095 - MSE: 0.46683839929519994 -Train Accuracy: 0.54545456\n",
      "epoch : 300 - cost: 0.68900925 - MSE: 0.4668383958887434 -Train Accuracy: 0.54545456\n",
      "epoch : 301 - cost: 0.6890095 - MSE: 0.4668384033767655 -Train Accuracy: 0.54545456\n",
      "epoch : 302 - cost: 0.68900925 - MSE: 0.4668383999703091 -Train Accuracy: 0.54545456\n",
      "epoch : 303 - cost: 0.68900925 - MSE: 0.4668384074583313 -Train Accuracy: 0.54545456\n",
      "epoch : 304 - cost: 0.6890095 - MSE: 0.466838414946354 -Train Accuracy: 0.54545456\n",
      "epoch : 305 - cost: 0.68900925 - MSE: 0.46683841153989714 -Train Accuracy: 0.54545456\n",
      "epoch : 306 - cost: 0.68900925 - MSE: 0.4668384190279199 -Train Accuracy: 0.54545456\n",
      "epoch : 307 - cost: 0.6890095 - MSE: 0.46683842651594254 -Train Accuracy: 0.54545456\n",
      "epoch : 308 - cost: 0.68900925 - MSE: 0.46683842310948576 -Train Accuracy: 0.54545456\n",
      "epoch : 309 - cost: 0.6890095 - MSE: 0.4668384305975085 -Train Accuracy: 0.54545456\n",
      "epoch : 310 - cost: 0.68900925 - MSE: 0.4668384271910516 -Train Accuracy: 0.54545456\n",
      "epoch : 311 - cost: 0.68900925 - MSE: 0.46683843467907443 -Train Accuracy: 0.54545456\n",
      "epoch : 312 - cost: 0.6890095 - MSE: 0.46683844216709774 -Train Accuracy: 0.54545456\n",
      "epoch : 313 - cost: 0.68900925 - MSE: 0.46683843876064046 -Train Accuracy: 0.54545456\n",
      "epoch : 314 - cost: 0.68900925 - MSE: 0.4668384462486636 -Train Accuracy: 0.54545456\n",
      "epoch : 315 - cost: 0.6890095 - MSE: 0.466838453736687 -Train Accuracy: 0.54545456\n",
      "epoch : 316 - cost: 0.68900925 - MSE: 0.4668384503302298 -Train Accuracy: 0.54545456\n",
      "epoch : 317 - cost: 0.6890095 - MSE: 0.46683845781825317 -Train Accuracy: 0.54545456\n",
      "epoch : 318 - cost: 0.68900925 - MSE: 0.46683845441179594 -Train Accuracy: 0.54545456\n",
      "epoch : 319 - cost: 0.68900925 - MSE: 0.4668384618998192 -Train Accuracy: 0.54545456\n",
      "epoch : 320 - cost: 0.6890095 - MSE: 0.46683846938784307 -Train Accuracy: 0.54545456\n",
      "epoch : 321 - cost: 0.68900925 - MSE: 0.4668384659813855 -Train Accuracy: 0.54545456\n",
      "epoch : 322 - cost: 0.68900925 - MSE: 0.46683847346940915 -Train Accuracy: 0.54545456\n",
      "epoch : 323 - cost: 0.6890095 - MSE: 0.4668384809574332 -Train Accuracy: 0.54545456\n",
      "epoch : 324 - cost: 0.68900925 - MSE: 0.4668384775509756 -Train Accuracy: 0.54545456\n",
      "epoch : 325 - cost: 0.6890095 - MSE: 0.4668384850389995 -Train Accuracy: 0.54545456\n",
      "epoch : 326 - cost: 0.68900925 - MSE: 0.466838481632542 -Train Accuracy: 0.54545456\n",
      "epoch : 327 - cost: 0.68900925 - MSE: 0.4668384891205659 -Train Accuracy: 0.54545456\n",
      "epoch : 328 - cost: 0.6890095 - MSE: 0.46683849660859017 -Train Accuracy: 0.54545456\n",
      "epoch : 329 - cost: 0.68900925 - MSE: 0.4668384932021323 -Train Accuracy: 0.54545456\n",
      "epoch : 330 - cost: 0.68900925 - MSE: 0.46683850069015664 -Train Accuracy: 0.54545456\n",
      "epoch : 331 - cost: 0.6890095 - MSE: 0.46683850817818107 -Train Accuracy: 0.54545456\n",
      "epoch : 332 - cost: 0.68900925 - MSE: 0.4668385047717231 -Train Accuracy: 0.54545456\n",
      "epoch : 333 - cost: 0.6890095 - MSE: 0.46683851225974765 -Train Accuracy: 0.54545456\n",
      "epoch : 334 - cost: 0.68900925 - MSE: 0.4668385088532897 -Train Accuracy: 0.54545456\n",
      "epoch : 335 - cost: 0.68900925 - MSE: 0.46683851634131424 -Train Accuracy: 0.54545456\n",
      "epoch : 336 - cost: 0.6890095 - MSE: 0.4668385238293392 -Train Accuracy: 0.54545456\n",
      "epoch : 337 - cost: 0.68900925 - MSE: 0.46683852042288104 -Train Accuracy: 0.54545456\n",
      "epoch : 338 - cost: 0.68900925 - MSE: 0.4668385279109059 -Train Accuracy: 0.54545456\n",
      "epoch : 339 - cost: 0.6890095 - MSE: 0.46683853539893083 -Train Accuracy: 0.54545456\n",
      "epoch : 340 - cost: 0.68900925 - MSE: 0.46683853199247255 -Train Accuracy: 0.54545456\n",
      "epoch : 341 - cost: 0.6890095 - MSE: 0.46683853948049775 -Train Accuracy: 0.54545456\n",
      "epoch : 342 - cost: 0.68900925 - MSE: 0.4668385360740396 -Train Accuracy: 0.54545456\n",
      "epoch : 343 - cost: 0.68900925 - MSE: 0.4668385435620645 -Train Accuracy: 0.54545456\n",
      "epoch : 344 - cost: 0.6890095 - MSE: 0.4668385510500898 -Train Accuracy: 0.54545456\n",
      "epoch : 345 - cost: 0.68900925 - MSE: 0.4668385476436314 -Train Accuracy: 0.54545456\n",
      "epoch : 346 - cost: 0.68900925 - MSE: 0.4668385551316569 -Train Accuracy: 0.54545456\n",
      "epoch : 347 - cost: 0.6890095 - MSE: 0.4668385626196824 -Train Accuracy: 0.54545456\n",
      "epoch : 348 - cost: 0.68900925 - MSE: 0.4668385592132238 -Train Accuracy: 0.54545456\n",
      "epoch : 349 - cost: 0.6890095 - MSE: 0.4668385667012495 -Train Accuracy: 0.54545456\n",
      "epoch : 350 - cost: 0.68900925 - MSE: 0.46683856329479073 -Train Accuracy: 0.54545456\n",
      "epoch : 351 - cost: 0.68900925 - MSE: 0.46683857078281626 -Train Accuracy: 0.54545456\n",
      "epoch : 352 - cost: 0.6890095 - MSE: 0.4668385782708426 -Train Accuracy: 0.54545456\n",
      "epoch : 353 - cost: 0.68900925 - MSE: 0.4668385748643835 -Train Accuracy: 0.54545456\n",
      "epoch : 354 - cost: 0.68900925 - MSE: 0.46683858235240966 -Train Accuracy: 0.54545456\n",
      "epoch : 355 - cost: 0.6890095 - MSE: 0.4668385898404357 -Train Accuracy: 0.54545456\n",
      "epoch : 356 - cost: 0.68900925 - MSE: 0.4668385864339768 -Train Accuracy: 0.54545456\n",
      "epoch : 357 - cost: 0.6890095 - MSE: 0.46683859392200294 -Train Accuracy: 0.54545456\n",
      "epoch : 358 - cost: 0.68900925 - MSE: 0.46683859051554405 -Train Accuracy: 0.54545456\n",
      "epoch : 359 - cost: 0.68900925 - MSE: 0.46683859800357025 -Train Accuracy: 0.54545456\n",
      "epoch : 360 - cost: 0.6890095 - MSE: 0.4668386054915967 -Train Accuracy: 0.54545456\n",
      "epoch : 361 - cost: 0.68900925 - MSE: 0.4668386020851375 -Train Accuracy: 0.54545456\n",
      "epoch : 362 - cost: 0.68900925 - MSE: 0.46683860957316414 -Train Accuracy: 0.54545456\n",
      "epoch : 363 - cost: 0.6890095 - MSE: 0.4668386170611908 -Train Accuracy: 0.54545456\n",
      "epoch : 364 - cost: 0.68900925 - MSE: 0.46683861365473145 -Train Accuracy: 0.54545456\n",
      "epoch : 365 - cost: 0.6890095 - MSE: 0.4668386211427582 -Train Accuracy: 0.54545456\n",
      "epoch : 366 - cost: 0.68900925 - MSE: 0.466838617736299 -Train Accuracy: 0.54545456\n",
      "epoch : 367 - cost: 0.68900925 - MSE: 0.4668386252243256 -Train Accuracy: 0.54545456\n",
      "epoch : 368 - cost: 0.6890095 - MSE: 0.4668386327123528 -Train Accuracy: 0.54545456\n",
      "epoch : 369 - cost: 0.68900925 - MSE: 0.46683862930589337 -Train Accuracy: 0.54545456\n",
      "epoch : 370 - cost: 0.68900925 - MSE: 0.46683863679392035 -Train Accuracy: 0.54545456\n",
      "epoch : 371 - cost: 0.6890095 - MSE: 0.46683864428194755 -Train Accuracy: 0.54545456\n",
      "epoch : 372 - cost: 0.68900925 - MSE: 0.46683864087548815 -Train Accuracy: 0.54545456\n",
      "epoch : 373 - cost: 0.6890095 - MSE: 0.46683864836351524 -Train Accuracy: 0.54545456\n",
      "epoch : 374 - cost: 0.68900925 - MSE: 0.4668386449570557 -Train Accuracy: 0.54545456\n",
      "epoch : 375 - cost: 0.68900925 - MSE: 0.466838652445083 -Train Accuracy: 0.54545456\n",
      "epoch : 376 - cost: 0.6890095 - MSE: 0.4668386599331107 -Train Accuracy: 0.54545456\n",
      "epoch : 377 - cost: 0.68900925 - MSE: 0.4668386565266509 -Train Accuracy: 0.54545456\n",
      "epoch : 378 - cost: 0.68900925 - MSE: 0.4668386640146784 -Train Accuracy: 0.54545456\n",
      "epoch : 379 - cost: 0.6890095 - MSE: 0.4668386715027062 -Train Accuracy: 0.54545456\n",
      "epoch : 380 - cost: 0.68900925 - MSE: 0.4668386680962463 -Train Accuracy: 0.54545456\n",
      "epoch : 381 - cost: 0.6890095 - MSE: 0.4668386755842743 -Train Accuracy: 0.54545456\n",
      "epoch : 382 - cost: 0.68900925 - MSE: 0.4668386721778142 -Train Accuracy: 0.54545456\n",
      "epoch : 383 - cost: 0.68900925 - MSE: 0.46683867966584197 -Train Accuracy: 0.54545456\n",
      "epoch : 384 - cost: 0.6890095 - MSE: 0.4668386871538703 -Train Accuracy: 0.54545456\n",
      "epoch : 385 - cost: 0.68900925 - MSE: 0.46683868374741 -Train Accuracy: 0.54545456\n",
      "epoch : 386 - cost: 0.68900925 - MSE: 0.4668386912354382 -Train Accuracy: 0.54545456\n",
      "epoch : 387 - cost: 0.6890095 - MSE: 0.4668386987234666 -Train Accuracy: 0.54545456\n",
      "epoch : 388 - cost: 0.68900925 - MSE: 0.4668386953170063 -Train Accuracy: 0.54545456\n",
      "epoch : 389 - cost: 0.6890095 - MSE: 0.4668387028050347 -Train Accuracy: 0.54545456\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch : 390 - cost: 0.68900925 - MSE: 0.4668386993985745 -Train Accuracy: 0.54545456\n",
      "epoch : 391 - cost: 0.68900925 - MSE: 0.4668387068866029 -Train Accuracy: 0.54545456\n",
      "epoch : 392 - cost: 0.6890095 - MSE: 0.46683871437463165 -Train Accuracy: 0.54545456\n",
      "epoch : 393 - cost: 0.68900925 - MSE: 0.4668387109681711 -Train Accuracy: 0.54545456\n",
      "epoch : 394 - cost: 0.68900925 - MSE: 0.4668387184561998 -Train Accuracy: 0.54545456\n",
      "epoch : 395 - cost: 0.6890095 - MSE: 0.4668387259442287 -Train Accuracy: 0.54545456\n",
      "epoch : 396 - cost: 0.68900925 - MSE: 0.4668387225377681 -Train Accuracy: 0.54545456\n",
      "epoch : 397 - cost: 0.6890095 - MSE: 0.46683873002579707 -Train Accuracy: 0.54545456\n",
      "epoch : 398 - cost: 0.68900925 - MSE: 0.4668387266193365 -Train Accuracy: 0.54545456\n",
      "epoch : 399 - cost: 0.68900925 - MSE: 0.4668387341073654 -Train Accuracy: 0.54545456\n",
      "epoch : 400 - cost: 0.6890095 - MSE: 0.4668387415953949 -Train Accuracy: 0.54545456\n",
      "epoch : 401 - cost: 0.68900925 - MSE: 0.466838738188934 -Train Accuracy: 0.54545456\n",
      "epoch : 402 - cost: 0.68900925 - MSE: 0.4668387456769634 -Train Accuracy: 0.54545456\n",
      "epoch : 403 - cost: 0.6890095 - MSE: 0.4668387531649927 -Train Accuracy: 0.54545456\n",
      "epoch : 404 - cost: 0.68900925 - MSE: 0.4668387497585318 -Train Accuracy: 0.54545456\n",
      "epoch : 405 - cost: 0.6890095 - MSE: 0.46683875724656143 -Train Accuracy: 0.54545456\n",
      "epoch : 406 - cost: 0.68900925 - MSE: 0.4668387538401005 -Train Accuracy: 0.54545456\n",
      "epoch : 407 - cost: 0.68900925 - MSE: 0.4668387613281299 -Train Accuracy: 0.54545456\n",
      "epoch : 408 - cost: 0.6890095 - MSE: 0.4668387688161598 -Train Accuracy: 0.54545456\n",
      "epoch : 409 - cost: 0.68900925 - MSE: 0.4668387654096985 -Train Accuracy: 0.54545456\n",
      "epoch : 410 - cost: 0.68900925 - MSE: 0.46683877289772857 -Train Accuracy: 0.54545456\n",
      "epoch : 411 - cost: 0.6890095 - MSE: 0.46683878038575843 -Train Accuracy: 0.54545456\n",
      "epoch : 412 - cost: 0.68900925 - MSE: 0.4668387769792971 -Train Accuracy: 0.54545456\n",
      "epoch : 413 - cost: 0.6890095 - MSE: 0.4668387844673273 -Train Accuracy: 0.54545456\n",
      "epoch : 414 - cost: 0.68900925 - MSE: 0.46683878106086596 -Train Accuracy: 0.54545456\n",
      "epoch : 415 - cost: 0.68900925 - MSE: 0.4668387885488959 -Train Accuracy: 0.54545456\n",
      "epoch : 416 - cost: 0.6890095 - MSE: 0.4668387960369266 -Train Accuracy: 0.54545456\n",
      "epoch : 417 - cost: 0.68900925 - MSE: 0.46683879263046485 -Train Accuracy: 0.54545456\n",
      "epoch : 418 - cost: 0.68900925 - MSE: 0.46683880011849554 -Train Accuracy: 0.54545456\n",
      "epoch : 419 - cost: 0.6890095 - MSE: 0.46683880760652596 -Train Accuracy: 0.54545456\n",
      "epoch : 420 - cost: 0.68900925 - MSE: 0.46683880420006446 -Train Accuracy: 0.54545456\n",
      "epoch : 421 - cost: 0.6890095 - MSE: 0.466838811688095 -Train Accuracy: 0.54545456\n",
      "epoch : 422 - cost: 0.68900925 - MSE: 0.46683880828163343 -Train Accuracy: 0.54545456\n",
      "epoch : 423 - cost: 0.68900925 - MSE: 0.4668388157696641 -Train Accuracy: 0.54545456\n",
      "epoch : 424 - cost: 0.6890095 - MSE: 0.46683882325769505 -Train Accuracy: 0.54545456\n",
      "epoch : 425 - cost: 0.68900925 - MSE: 0.4668388198512331 -Train Accuracy: 0.54545456\n",
      "epoch : 426 - cost: 0.68900925 - MSE: 0.46683882733926413 -Train Accuracy: 0.54545456\n",
      "epoch : 427 - cost: 0.6890095 - MSE: 0.46683883482729527 -Train Accuracy: 0.54545456\n",
      "epoch : 428 - cost: 0.68900925 - MSE: 0.4668388314208333 -Train Accuracy: 0.54545456\n",
      "epoch : 429 - cost: 0.6890095 - MSE: 0.46683883890886435 -Train Accuracy: 0.54545456\n",
      "epoch : 430 - cost: 0.68900925 - MSE: 0.46683883550240257 -Train Accuracy: 0.54545456\n",
      "epoch : 431 - cost: 0.68900925 - MSE: 0.46683884299043366 -Train Accuracy: 0.54545456\n",
      "epoch : 432 - cost: 0.6890095 - MSE: 0.46683885047846524 -Train Accuracy: 0.54545456\n",
      "epoch : 433 - cost: 0.68900925 - MSE: 0.4668388470720031 -Train Accuracy: 0.54545456\n",
      "epoch : 434 - cost: 0.68900925 - MSE: 0.4668388545600347 -Train Accuracy: 0.54545456\n",
      "epoch : 435 - cost: 0.6890095 - MSE: 0.46683886204806624 -Train Accuracy: 0.54545456\n",
      "epoch : 436 - cost: 0.68900925 - MSE: 0.4668388586416042 -Train Accuracy: 0.54545456\n",
      "epoch : 437 - cost: 0.6890095 - MSE: 0.46683886612963577 -Train Accuracy: 0.54545456\n",
      "epoch : 438 - cost: 0.68900925 - MSE: 0.46683886272317354 -Train Accuracy: 0.54545456\n",
      "epoch : 439 - cost: 0.68900925 - MSE: 0.46683887021120524 -Train Accuracy: 0.54545456\n",
      "epoch : 440 - cost: 0.6890095 - MSE: 0.46683887769923743 -Train Accuracy: 0.54545456\n",
      "epoch : 441 - cost: 0.68900925 - MSE: 0.4668388742927749 -Train Accuracy: 0.54545456\n",
      "epoch : 442 - cost: 0.68900925 - MSE: 0.4668388817808069 -Train Accuracy: 0.54545456\n",
      "epoch : 443 - cost: 0.6890095 - MSE: 0.4668388892688391 -Train Accuracy: 0.54545456\n",
      "epoch : 444 - cost: 0.68900925 - MSE: 0.4668388858623766 -Train Accuracy: 0.54545456\n",
      "epoch : 445 - cost: 0.6890095 - MSE: 0.4668388933504089 -Train Accuracy: 0.54545456\n",
      "epoch : 446 - cost: 0.68900925 - MSE: 0.46683888994394623 -Train Accuracy: 0.54545456\n",
      "epoch : 447 - cost: 0.68900925 - MSE: 0.46683889743197843 -Train Accuracy: 0.54545456\n",
      "epoch : 448 - cost: 0.6890095 - MSE: 0.4668389049200111 -Train Accuracy: 0.54545456\n",
      "epoch : 449 - cost: 0.68900925 - MSE: 0.4668389015135483 -Train Accuracy: 0.54545456\n",
      "epoch : 450 - cost: 0.68900925 - MSE: 0.4668389090015809 -Train Accuracy: 0.54545456\n",
      "epoch : 451 - cost: 0.6890095 - MSE: 0.46683891648961373 -Train Accuracy: 0.54545456\n",
      "epoch : 452 - cost: 0.68900925 - MSE: 0.4668389130831508 -Train Accuracy: 0.54545456\n",
      "epoch : 453 - cost: 0.6890095 - MSE: 0.4668389205711836 -Train Accuracy: 0.54545456\n",
      "epoch : 454 - cost: 0.68900925 - MSE: 0.4668389171647207 -Train Accuracy: 0.54545456\n",
      "epoch : 455 - cost: 0.68900925 - MSE: 0.46683892465275356 -Train Accuracy: 0.54545456\n",
      "epoch : 456 - cost: 0.6890095 - MSE: 0.46683893214078676 -Train Accuracy: 0.54545456\n",
      "epoch : 457 - cost: 0.68900925 - MSE: 0.46683892873432353 -Train Accuracy: 0.54545456\n",
      "epoch : 458 - cost: 0.68900925 - MSE: 0.4668389362223567 -Train Accuracy: 0.54545456\n",
      "epoch : 459 - cost: 0.6890095 - MSE: 0.46683894371039003 -Train Accuracy: 0.54545456\n",
      "epoch : 460 - cost: 0.68900925 - MSE: 0.4668389403039267 -Train Accuracy: 0.54545456\n",
      "epoch : 461 - cost: 0.6890095 - MSE: 0.46683894779196017 -Train Accuracy: 0.54545456\n",
      "epoch : 462 - cost: 0.68900925 - MSE: 0.4668389443854969 -Train Accuracy: 0.54545456\n",
      "epoch : 463 - cost: 0.68900925 - MSE: 0.4668389518735303 -Train Accuracy: 0.54545456\n",
      "epoch : 464 - cost: 0.6890095 - MSE: 0.4668389593615642 -Train Accuracy: 0.54545456\n",
      "epoch : 465 - cost: 0.68900925 - MSE: 0.46683895595510067 -Train Accuracy: 0.54545456\n",
      "epoch : 466 - cost: 0.68900925 - MSE: 0.4668389634431344 -Train Accuracy: 0.54545456\n",
      "epoch : 467 - cost: 0.6890095 - MSE: 0.4668389709311682 -Train Accuracy: 0.54545456\n",
      "epoch : 468 - cost: 0.68900925 - MSE: 0.4668389675247046 -Train Accuracy: 0.54545456\n",
      "epoch : 469 - cost: 0.6890095 - MSE: 0.4668389750127387 -Train Accuracy: 0.54545456\n",
      "epoch : 470 - cost: 0.68900925 - MSE: 0.4668389716062752 -Train Accuracy: 0.54545456\n",
      "epoch : 471 - cost: 0.68900925 - MSE: 0.466838979094309 -Train Accuracy: 0.54545456\n",
      "epoch : 472 - cost: 0.6890095 - MSE: 0.4668389865823433 -Train Accuracy: 0.54545456\n",
      "epoch : 473 - cost: 0.68900925 - MSE: 0.46683898317587946 -Train Accuracy: 0.54545456\n",
      "epoch : 474 - cost: 0.68900925 - MSE: 0.4668389906639139 -Train Accuracy: 0.54545456\n",
      "epoch : 475 - cost: 0.6890095 - MSE: 0.4668389981519482 -Train Accuracy: 0.54545456\n",
      "epoch : 476 - cost: 0.68900925 - MSE: 0.46683899474548424 -Train Accuracy: 0.54545456\n",
      "epoch : 477 - cost: 0.6890095 - MSE: 0.46683900223351893 -Train Accuracy: 0.54545456\n",
      "epoch : 478 - cost: 0.68900925 - MSE: 0.4668389988270548 -Train Accuracy: 0.54545456\n",
      "epoch : 479 - cost: 0.68900925 - MSE: 0.46683900631508923 -Train Accuracy: 0.54545456\n",
      "epoch : 480 - cost: 0.6890095 - MSE: 0.46683901380312437 -Train Accuracy: 0.54545456\n",
      "epoch : 481 - cost: 0.68900925 - MSE: 0.46683901039666004 -Train Accuracy: 0.54545456\n",
      "epoch : 482 - cost: 0.68900925 - MSE: 0.466839017884695 -Train Accuracy: 0.54545456\n",
      "epoch : 483 - cost: 0.6890095 - MSE: 0.4668390253727299 -Train Accuracy: 0.54545456\n",
      "epoch : 484 - cost: 0.68900925 - MSE: 0.46683902196626575 -Train Accuracy: 0.54545456\n",
      "epoch : 485 - cost: 0.6890095 - MSE: 0.4668390294543007 -Train Accuracy: 0.54545456\n",
      "epoch : 486 - cost: 0.68900925 - MSE: 0.4668390260478366 -Train Accuracy: 0.54545456\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch : 487 - cost: 0.68900925 - MSE: 0.46683903353587164 -Train Accuracy: 0.54545456\n",
      "epoch : 488 - cost: 0.6890095 - MSE: 0.46683904102390694 -Train Accuracy: 0.54545456\n",
      "epoch : 489 - cost: 0.68900925 - MSE: 0.46683903761744244 -Train Accuracy: 0.54545456\n",
      "epoch : 490 - cost: 0.68900925 - MSE: 0.4668390451054779 -Train Accuracy: 0.54545456\n",
      "epoch : 491 - cost: 0.6890095 - MSE: 0.46683905259351344 -Train Accuracy: 0.54545456\n",
      "epoch : 492 - cost: 0.68900925 - MSE: 0.4668390491870489 -Train Accuracy: 0.54545456\n",
      "epoch : 493 - cost: 0.6890095 - MSE: 0.4668390566750844 -Train Accuracy: 0.54545456\n",
      "epoch : 494 - cost: 0.68900925 - MSE: 0.46683905326861985 -Train Accuracy: 0.54545456\n",
      "epoch : 495 - cost: 0.68900925 - MSE: 0.4668390607566554 -Train Accuracy: 0.54545456\n",
      "epoch : 496 - cost: 0.6890095 - MSE: 0.46683906824469146 -Train Accuracy: 0.54545456\n",
      "epoch : 497 - cost: 0.68900925 - MSE: 0.4668390648382267 -Train Accuracy: 0.54545456\n",
      "epoch : 498 - cost: 0.68900925 - MSE: 0.46683907232626254 -Train Accuracy: 0.54545456\n",
      "epoch : 499 - cost: 0.6890095 - MSE: 0.4668390798142986 -Train Accuracy: 0.54545456\n",
      "epoch : 500 - cost: 0.68900925 - MSE: 0.46683907640783384 -Train Accuracy: 0.54545456\n",
      "epoch : 501 - cost: 0.6890095 - MSE: 0.46683908389586987 -Train Accuracy: 0.54545456\n",
      "epoch : 502 - cost: 0.68900925 - MSE: 0.466839080489405 -Train Accuracy: 0.54545456\n",
      "epoch : 503 - cost: 0.68900925 - MSE: 0.46683908797744117 -Train Accuracy: 0.54545456\n",
      "epoch : 504 - cost: 0.6890095 - MSE: 0.46683909546547786 -Train Accuracy: 0.54545456\n",
      "epoch : 505 - cost: 0.68900925 - MSE: 0.46683909205901264 -Train Accuracy: 0.54545456\n",
      "epoch : 506 - cost: 0.68900925 - MSE: 0.466839099547049 -Train Accuracy: 0.54545456\n",
      "epoch : 507 - cost: 0.6890095 - MSE: 0.4668391070350857 -Train Accuracy: 0.54545456\n",
      "epoch : 508 - cost: 0.68900925 - MSE: 0.46683910362862047 -Train Accuracy: 0.54545456\n",
      "epoch : 509 - cost: 0.6890095 - MSE: 0.4668391111166573 -Train Accuracy: 0.54545456\n",
      "epoch : 510 - cost: 0.68900925 - MSE: 0.466839107710192 -Train Accuracy: 0.54545456\n",
      "epoch : 511 - cost: 0.68900925 - MSE: 0.46683911519822857 -Train Accuracy: 0.54545456\n",
      "epoch : 512 - cost: 0.6890095 - MSE: 0.4668391226862657 -Train Accuracy: 0.54545456\n",
      "epoch : 513 - cost: 0.68900925 - MSE: 0.46683911927980015 -Train Accuracy: 0.54545456\n",
      "epoch : 514 - cost: 0.68900925 - MSE: 0.46683912676783734 -Train Accuracy: 0.54545456\n",
      "epoch : 515 - cost: 0.6890095 - MSE: 0.46683913425587453 -Train Accuracy: 0.54545456\n",
      "epoch : 516 - cost: 0.68900925 - MSE: 0.466839130849409 -Train Accuracy: 0.54545456\n",
      "epoch : 517 - cost: 0.6890095 - MSE: 0.46683913833744617 -Train Accuracy: 0.54545456\n",
      "epoch : 518 - cost: 0.68900925 - MSE: 0.46683913493098067 -Train Accuracy: 0.54545456\n",
      "epoch : 519 - cost: 0.68900925 - MSE: 0.4668391424190179 -Train Accuracy: 0.54545456\n",
      "epoch : 520 - cost: 0.6890095 - MSE: 0.46683914990705555 -Train Accuracy: 0.54545456\n",
      "epoch : 521 - cost: 0.68900925 - MSE: 0.46683914650058966 -Train Accuracy: 0.54545456\n",
      "epoch : 522 - cost: 0.68900925 - MSE: 0.46683915398862735 -Train Accuracy: 0.54545456\n",
      "epoch : 523 - cost: 0.6890095 - MSE: 0.46683916147666504 -Train Accuracy: 0.54545456\n",
      "epoch : 524 - cost: 0.68900925 - MSE: 0.4668391580701991 -Train Accuracy: 0.54545456\n",
      "epoch : 525 - cost: 0.6890095 - MSE: 0.46683916555823696 -Train Accuracy: 0.54545456\n",
      "epoch : 526 - cost: 0.68900925 - MSE: 0.466839162151771 -Train Accuracy: 0.54545456\n",
      "epoch : 527 - cost: 0.68900925 - MSE: 0.46683916963980887 -Train Accuracy: 0.54545456\n",
      "epoch : 528 - cost: 0.6890095 - MSE: 0.4668391771278473 -Train Accuracy: 0.54545456\n",
      "epoch : 529 - cost: 0.68900925 - MSE: 0.46683917372138106 -Train Accuracy: 0.54545456\n",
      "epoch : 530 - cost: 0.68900925 - MSE: 0.46683918120941925 -Train Accuracy: 0.54545456\n",
      "epoch : 531 - cost: 0.6890095 - MSE: 0.46683918869745744 -Train Accuracy: 0.54545456\n",
      "epoch : 532 - cost: 0.68900925 - MSE: 0.4668391852909912 -Train Accuracy: 0.54545456\n",
      "epoch : 533 - cost: 0.6890095 - MSE: 0.4668391927790298 -Train Accuracy: 0.54545456\n",
      "epoch : 534 - cost: 0.68900925 - MSE: 0.46683918937256347 -Train Accuracy: 0.54545456\n",
      "epoch : 535 - cost: 0.68900925 - MSE: 0.46683919686060177 -Train Accuracy: 0.54545456\n",
      "epoch : 536 - cost: 0.6890095 - MSE: 0.4668392043486405 -Train Accuracy: 0.54545456\n",
      "epoch : 537 - cost: 0.68900925 - MSE: 0.46683920094217396 -Train Accuracy: 0.54545456\n",
      "epoch : 538 - cost: 0.68900925 - MSE: 0.4668392084302128 -Train Accuracy: 0.54545456\n",
      "epoch : 539 - cost: 0.6890095 - MSE: 0.4668392159182516 -Train Accuracy: 0.54545456\n",
      "epoch : 540 - cost: 0.68900925 - MSE: 0.466839212511785 -Train Accuracy: 0.54545456\n",
      "epoch : 541 - cost: 0.6890095 - MSE: 0.46683921999982403 -Train Accuracy: 0.54545456\n",
      "epoch : 542 - cost: 0.68900925 - MSE: 0.4668392165933573 -Train Accuracy: 0.54545456\n",
      "epoch : 543 - cost: 0.68900925 - MSE: 0.4668392240813962 -Train Accuracy: 0.54545456\n",
      "epoch : 544 - cost: 0.6890095 - MSE: 0.46683923156943574 -Train Accuracy: 0.54545456\n",
      "epoch : 545 - cost: 0.68900925 - MSE: 0.4668392281629687 -Train Accuracy: 0.54545456\n",
      "epoch : 546 - cost: 0.68900925 - MSE: 0.46683923565100827 -Train Accuracy: 0.54545456\n",
      "epoch : 547 - cost: 0.6890095 - MSE: 0.46683924313904757 -Train Accuracy: 0.54545456\n",
      "epoch : 548 - cost: 0.68900925 - MSE: 0.4668392397325808 -Train Accuracy: 0.54545456\n",
      "epoch : 549 - cost: 0.6890095 - MSE: 0.46683924722062015 -Train Accuracy: 0.54545456\n",
      "epoch : 550 - cost: 0.68900925 - MSE: 0.46683924381415326 -Train Accuracy: 0.54545456\n",
      "epoch : 551 - cost: 0.68900925 - MSE: 0.46683925130219284 -Train Accuracy: 0.54545456\n",
      "epoch : 552 - cost: 0.6890095 - MSE: 0.46683925879023275 -Train Accuracy: 0.54545456\n",
      "epoch : 553 - cost: 0.68900925 - MSE: 0.4668392553837654 -Train Accuracy: 0.54545456\n",
      "epoch : 554 - cost: 0.68900925 - MSE: 0.4668392628718053 -Train Accuracy: 0.54545456\n",
      "epoch : 555 - cost: 0.6890095 - MSE: 0.4668392703598453 -Train Accuracy: 0.54545456\n",
      "epoch : 556 - cost: 0.68900925 - MSE: 0.4668392669533781 -Train Accuracy: 0.54545456\n",
      "epoch : 557 - cost: 0.6890095 - MSE: 0.466839274441418 -Train Accuracy: 0.54545456\n",
      "epoch : 558 - cost: 0.68900925 - MSE: 0.4668392710349509 -Train Accuracy: 0.54545456\n",
      "epoch : 559 - cost: 0.68900925 - MSE: 0.4668392785229908 -Train Accuracy: 0.54545456\n",
      "epoch : 560 - cost: 0.6890095 - MSE: 0.4668392860110313 -Train Accuracy: 0.54545456\n",
      "epoch : 561 - cost: 0.68900925 - MSE: 0.4668392826045638 -Train Accuracy: 0.54545456\n",
      "epoch : 562 - cost: 0.68900925 - MSE: 0.4668392900926043 -Train Accuracy: 0.54545456\n",
      "epoch : 563 - cost: 0.6890095 - MSE: 0.4668392975806447 -Train Accuracy: 0.54545456\n",
      "epoch : 564 - cost: 0.68900925 - MSE: 0.4668392941741773 -Train Accuracy: 0.54545456\n",
      "epoch : 565 - cost: 0.6890095 - MSE: 0.4668393016622178 -Train Accuracy: 0.54545456\n",
      "epoch : 566 - cost: 0.68900925 - MSE: 0.4668392982557502 -Train Accuracy: 0.54545456\n",
      "epoch : 567 - cost: 0.68900925 - MSE: 0.4668393057437908 -Train Accuracy: 0.54545456\n",
      "epoch : 568 - cost: 0.6890095 - MSE: 0.4668393132318319 -Train Accuracy: 0.54545456\n",
      "epoch : 569 - cost: 0.68900925 - MSE: 0.466839309825364 -Train Accuracy: 0.54545456\n",
      "epoch : 570 - cost: 0.68900925 - MSE: 0.4668393173134049 -Train Accuracy: 0.54545456\n",
      "epoch : 571 - cost: 0.6890095 - MSE: 0.46683932480144597 -Train Accuracy: 0.54545456\n",
      "epoch : 572 - cost: 0.68900925 - MSE: 0.46683932139497814 -Train Accuracy: 0.54545456\n",
      "epoch : 573 - cost: 0.6890095 - MSE: 0.4668393288830193 -Train Accuracy: 0.54545456\n",
      "epoch : 574 - cost: 0.68900925 - MSE: 0.46683932547655144 -Train Accuracy: 0.54545456\n",
      "epoch : 575 - cost: 0.68900925 - MSE: 0.4668393329645924 -Train Accuracy: 0.54545456\n",
      "epoch : 576 - cost: 0.6890095 - MSE: 0.4668393404526341 -Train Accuracy: 0.54545456\n",
      "epoch : 577 - cost: 0.68900925 - MSE: 0.46683933704616587 -Train Accuracy: 0.54545456\n",
      "epoch : 578 - cost: 0.68900925 - MSE: 0.4668393445342073 -Train Accuracy: 0.54545456\n",
      "epoch : 579 - cost: 0.6890095 - MSE: 0.466839352022249 -Train Accuracy: 0.54545456\n",
      "epoch : 580 - cost: 0.68900925 - MSE: 0.4668393486157808 -Train Accuracy: 0.54545456\n",
      "epoch : 581 - cost: 0.6890095 - MSE: 0.4668393561038225 -Train Accuracy: 0.54545456\n",
      "epoch : 582 - cost: 0.68900925 - MSE: 0.4668393526973543 -Train Accuracy: 0.54545456\n",
      "epoch : 583 - cost: 0.68900925 - MSE: 0.46683936018539596 -Train Accuracy: 0.54545456\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch : 584 - cost: 0.6890095 - MSE: 0.466839367673438 -Train Accuracy: 0.54545456\n",
      "epoch : 585 - cost: 0.68900925 - MSE: 0.4668393642669695 -Train Accuracy: 0.54545456\n",
      "epoch : 586 - cost: 0.68900925 - MSE: 0.4668393717550116 -Train Accuracy: 0.54545456\n",
      "epoch : 587 - cost: 0.6890095 - MSE: 0.4668393792430538 -Train Accuracy: 0.54545456\n",
      "epoch : 588 - cost: 0.68900925 - MSE: 0.4668393758365852 -Train Accuracy: 0.54545456\n",
      "epoch : 589 - cost: 0.6890095 - MSE: 0.4668393833246275 -Train Accuracy: 0.54545456\n",
      "epoch : 590 - cost: 0.68900925 - MSE: 0.4668393799181589 -Train Accuracy: 0.54545456\n",
      "epoch : 591 - cost: 0.68900925 - MSE: 0.4668393874062011 -Train Accuracy: 0.54545456\n",
      "epoch : 592 - cost: 0.6890095 - MSE: 0.4668393948942439 -Train Accuracy: 0.54545456\n",
      "epoch : 593 - cost: 0.68900925 - MSE: 0.4668393914877751 -Train Accuracy: 0.54545456\n",
      "epoch : 594 - cost: 0.68900925 - MSE: 0.46683939897581767 -Train Accuracy: 0.54545456\n",
      "epoch : 595 - cost: 0.6890095 - MSE: 0.4668394064638604 -Train Accuracy: 0.54545456\n",
      "epoch : 596 - cost: 0.68900925 - MSE: 0.46683940305739147 -Train Accuracy: 0.54545456\n",
      "epoch : 597 - cost: 0.6890095 - MSE: 0.46683941054543443 -Train Accuracy: 0.54545456\n",
      "epoch : 598 - cost: 0.68900925 - MSE: 0.46683940713896555 -Train Accuracy: 0.54545456\n",
      "epoch : 599 - cost: 0.68900925 - MSE: 0.46683941462700823 -Train Accuracy: 0.54545456\n",
      "epoch : 600 - cost: 0.6890095 - MSE: 0.46683942211505136 -Train Accuracy: 0.54545456\n",
      "epoch : 601 - cost: 0.68900925 - MSE: 0.46683941870858225 -Train Accuracy: 0.54545456\n",
      "epoch : 602 - cost: 0.68900925 - MSE: 0.46683942619662555 -Train Accuracy: 0.54545456\n",
      "epoch : 603 - cost: 0.6890095 - MSE: 0.46683943368466874 -Train Accuracy: 0.54545456\n",
      "epoch : 604 - cost: 0.68900925 - MSE: 0.4668394302781996 -Train Accuracy: 0.54545456\n",
      "epoch : 605 - cost: 0.6890095 - MSE: 0.46683943776624304 -Train Accuracy: 0.54545456\n",
      "epoch : 606 - cost: 0.68900925 - MSE: 0.4668394343597736 -Train Accuracy: 0.54545456\n",
      "epoch : 607 - cost: 0.68900925 - MSE: 0.4668394418478169 -Train Accuracy: 0.54545456\n",
      "epoch : 608 - cost: 0.6890095 - MSE: 0.4668394493358609 -Train Accuracy: 0.54545456\n",
      "epoch : 609 - cost: 0.68900925 - MSE: 0.46683944592939125 -Train Accuracy: 0.54545456\n",
      "epoch : 610 - cost: 0.68900925 - MSE: 0.4668394534174351 -Train Accuracy: 0.54545456\n",
      "epoch : 611 - cost: 0.6890095 - MSE: 0.4668394609054789 -Train Accuracy: 0.54545456\n",
      "epoch : 612 - cost: 0.68900925 - MSE: 0.4668394574990094 -Train Accuracy: 0.54545456\n",
      "epoch : 613 - cost: 0.6890095 - MSE: 0.46683946498705325 -Train Accuracy: 0.54545456\n",
      "epoch : 614 - cost: 0.68900925 - MSE: 0.46683946158058376 -Train Accuracy: 0.54545456\n",
      "epoch : 615 - cost: 0.68900925 - MSE: 0.4668394690686277 -Train Accuracy: 0.54545456\n",
      "epoch : 616 - cost: 0.6890095 - MSE: 0.46683947655667196 -Train Accuracy: 0.54545456\n",
      "epoch : 617 - cost: 0.68900925 - MSE: 0.4668394731502021 -Train Accuracy: 0.54545456\n",
      "epoch : 618 - cost: 0.68900925 - MSE: 0.4668394806382465 -Train Accuracy: 0.54545456\n",
      "epoch : 619 - cost: 0.6890095 - MSE: 0.46683948812629084 -Train Accuracy: 0.54545456\n",
      "epoch : 620 - cost: 0.68900925 - MSE: 0.4668394847198209 -Train Accuracy: 0.54545456\n",
      "epoch : 621 - cost: 0.6890095 - MSE: 0.46683949220786536 -Train Accuracy: 0.54545456\n",
      "epoch : 622 - cost: 0.68900925 - MSE: 0.46683948880139553 -Train Accuracy: 0.54545456\n",
      "epoch : 623 - cost: 0.68900925 - MSE: 0.4668394962894399 -Train Accuracy: 0.54545456\n",
      "epoch : 624 - cost: 0.6890095 - MSE: 0.4668395037774849 -Train Accuracy: 0.54545456\n",
      "epoch : 625 - cost: 0.68900925 - MSE: 0.4668395003710148 -Train Accuracy: 0.54545456\n",
      "epoch : 626 - cost: 0.68900925 - MSE: 0.4668395078590595 -Train Accuracy: 0.54545456\n",
      "epoch : 627 - cost: 0.6890095 - MSE: 0.4668395153471045 -Train Accuracy: 0.54545456\n",
      "epoch : 628 - cost: 0.68900925 - MSE: 0.46683951194063444 -Train Accuracy: 0.54545456\n",
      "epoch : 629 - cost: 0.6890095 - MSE: 0.46683951942867924 -Train Accuracy: 0.54545456\n",
      "epoch : 630 - cost: 0.68900925 - MSE: 0.4668395160222091 -Train Accuracy: 0.54545456\n",
      "epoch : 631 - cost: 0.68900925 - MSE: 0.46683952351025415 -Train Accuracy: 0.54545456\n",
      "epoch : 632 - cost: 0.6890095 - MSE: 0.4668395309982996 -Train Accuracy: 0.54545456\n",
      "epoch : 633 - cost: 0.68900925 - MSE: 0.4668395275918292 -Train Accuracy: 0.54545456\n",
      "epoch : 634 - cost: 0.68900925 - MSE: 0.4668395350798744 -Train Accuracy: 0.54545456\n",
      "epoch : 635 - cost: 0.6890095 - MSE: 0.46683954256792 -Train Accuracy: 0.54545456\n",
      "epoch : 636 - cost: 0.68900925 - MSE: 0.46683953916144943 -Train Accuracy: 0.54545456\n",
      "epoch : 637 - cost: 0.6890095 - MSE: 0.4668395466494952 -Train Accuracy: 0.54545456\n",
      "epoch : 638 - cost: 0.68900925 - MSE: 0.46683954324302446 -Train Accuracy: 0.54545456\n",
      "epoch : 639 - cost: 0.68900925 - MSE: 0.46683955073107 -Train Accuracy: 0.54545456\n",
      "epoch : 640 - cost: 0.6890095 - MSE: 0.46683955821911605 -Train Accuracy: 0.54545456\n",
      "epoch : 641 - cost: 0.68900925 - MSE: 0.46683955481264505 -Train Accuracy: 0.54545456\n",
      "epoch : 642 - cost: 0.68900925 - MSE: 0.46683956230069107 -Train Accuracy: 0.54545456\n",
      "epoch : 643 - cost: 0.6890095 - MSE: 0.4668395697887372 -Train Accuracy: 0.54545456\n",
      "epoch : 644 - cost: 0.68900925 - MSE: 0.46683956638226626 -Train Accuracy: 0.54545456\n",
      "epoch : 645 - cost: 0.6890095 - MSE: 0.46683957387031244 -Train Accuracy: 0.54545456\n",
      "epoch : 646 - cost: 0.68900925 - MSE: 0.46683957046384156 -Train Accuracy: 0.54545456\n",
      "epoch : 647 - cost: 0.68900925 - MSE: 0.46683957795188774 -Train Accuracy: 0.54545456\n",
      "epoch : 648 - cost: 0.6890095 - MSE: 0.4668395854399342 -Train Accuracy: 0.54545456\n",
      "epoch : 649 - cost: 0.68900925 - MSE: 0.466839582033463 -Train Accuracy: 0.54545456\n",
      "epoch : 650 - cost: 0.68900925 - MSE: 0.4668395895215095 -Train Accuracy: 0.54545456\n",
      "epoch : 651 - cost: 0.6890095 - MSE: 0.4668395970095562 -Train Accuracy: 0.54545456\n",
      "epoch : 652 - cost: 0.68900925 - MSE: 0.46683959360308486 -Train Accuracy: 0.54545456\n",
      "epoch : 653 - cost: 0.6890095 - MSE: 0.46683960109113165 -Train Accuracy: 0.54545456\n",
      "epoch : 654 - cost: 0.68900925 - MSE: 0.46683959768466043 -Train Accuracy: 0.54545456\n",
      "epoch : 655 - cost: 0.68900925 - MSE: 0.4668396051727071 -Train Accuracy: 0.54545456\n",
      "epoch : 656 - cost: 0.6890095 - MSE: 0.46683961266075436 -Train Accuracy: 0.54545456\n",
      "epoch : 657 - cost: 0.68900925 - MSE: 0.4668396092542828 -Train Accuracy: 0.54545456\n",
      "epoch : 658 - cost: 0.68900925 - MSE: 0.4668396167423299 -Train Accuracy: 0.54545456\n",
      "epoch : 659 - cost: 0.6890095 - MSE: 0.466839624230377 -Train Accuracy: 0.54545456\n",
      "epoch : 660 - cost: 0.68900925 - MSE: 0.46683962082390545 -Train Accuracy: 0.54545456\n",
      "epoch : 661 - cost: 0.6890095 - MSE: 0.46683962831195286 -Train Accuracy: 0.54545456\n",
      "epoch : 662 - cost: 0.68900925 - MSE: 0.46683962490548125 -Train Accuracy: 0.54545456\n",
      "epoch : 663 - cost: 0.68900925 - MSE: 0.46683963239352844 -Train Accuracy: 0.54545456\n",
      "epoch : 664 - cost: 0.6890095 - MSE: 0.4668396398815761 -Train Accuracy: 0.54545456\n",
      "epoch : 665 - cost: 0.68900925 - MSE: 0.4668396364751041 -Train Accuracy: 0.54545456\n",
      "epoch : 666 - cost: 0.68900925 - MSE: 0.466839643963152 -Train Accuracy: 0.54545456\n",
      "epoch : 667 - cost: 0.6890095 - MSE: 0.4668396514511996 -Train Accuracy: 0.54545456\n",
      "epoch : 668 - cost: 0.68900925 - MSE: 0.4668396480447276 -Train Accuracy: 0.54545456\n",
      "epoch : 669 - cost: 0.6890095 - MSE: 0.46683965553277557 -Train Accuracy: 0.54545456\n",
      "epoch : 670 - cost: 0.68900925 - MSE: 0.4668396521263036 -Train Accuracy: 0.54545456\n",
      "epoch : 671 - cost: 0.68900925 - MSE: 0.46683965961435125 -Train Accuracy: 0.54545456\n",
      "epoch : 672 - cost: 0.6890095 - MSE: 0.4668396671023997 -Train Accuracy: 0.54545456\n",
      "epoch : 673 - cost: 0.68900925 - MSE: 0.46683966369592733 -Train Accuracy: 0.54545456\n",
      "epoch : 674 - cost: 0.68900925 - MSE: 0.46683967118397574 -Train Accuracy: 0.54545456\n",
      "epoch : 675 - cost: 0.6890095 - MSE: 0.46683967867202397 -Train Accuracy: 0.54545456\n",
      "epoch : 676 - cost: 0.68900925 - MSE: 0.4668396752655518 -Train Accuracy: 0.54545456\n",
      "epoch : 677 - cost: 0.6890095 - MSE: 0.4668396827536001 -Train Accuracy: 0.54545456\n",
      "epoch : 678 - cost: 0.68900925 - MSE: 0.46683967934712783 -Train Accuracy: 0.54545456\n",
      "epoch : 679 - cost: 0.68900925 - MSE: 0.4668396868351763 -Train Accuracy: 0.54545456\n",
      "epoch : 680 - cost: 0.6890095 - MSE: 0.46683969432322503 -Train Accuracy: 0.54545456\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch : 681 - cost: 0.68900925 - MSE: 0.4668396909167524 -Train Accuracy: 0.54545456\n",
      "epoch : 682 - cost: 0.68900925 - MSE: 0.4668396984048012 -Train Accuracy: 0.54545456\n",
      "epoch : 683 - cost: 0.6890095 - MSE: 0.46683970589285007 -Train Accuracy: 0.54545456\n",
      "epoch : 684 - cost: 0.68900925 - MSE: 0.4668397024863775 -Train Accuracy: 0.54545456\n",
      "epoch : 685 - cost: 0.6890095 - MSE: 0.4668397099744263 -Train Accuracy: 0.54545456\n",
      "epoch : 686 - cost: 0.68900925 - MSE: 0.4668397065679538 -Train Accuracy: 0.54545456\n",
      "epoch : 687 - cost: 0.68900925 - MSE: 0.4668397140560027 -Train Accuracy: 0.54545456\n",
      "epoch : 688 - cost: 0.6890095 - MSE: 0.46683972154405207 -Train Accuracy: 0.54545456\n",
      "epoch : 689 - cost: 0.68900925 - MSE: 0.46683971813757924 -Train Accuracy: 0.54545456\n",
      "epoch : 690 - cost: 0.68900925 - MSE: 0.46683972562562864 -Train Accuracy: 0.54545456\n",
      "epoch : 691 - cost: 0.6890095 - MSE: 0.46683973311367793 -Train Accuracy: 0.54545456\n",
      "epoch : 692 - cost: 0.68900925 - MSE: 0.4668397297072052 -Train Accuracy: 0.54545456\n",
      "epoch : 693 - cost: 0.6890095 - MSE: 0.46683973719525457 -Train Accuracy: 0.54545456\n",
      "epoch : 694 - cost: 0.68900925 - MSE: 0.4668397337887817 -Train Accuracy: 0.54545456\n",
      "epoch : 695 - cost: 0.68900925 - MSE: 0.46683974127683114 -Train Accuracy: 0.54545456\n",
      "epoch : 696 - cost: 0.6890095 - MSE: 0.4668397487648811 -Train Accuracy: 0.54545456\n",
      "epoch : 697 - cost: 0.68900925 - MSE: 0.46683974535840783 -Train Accuracy: 0.54545456\n",
      "epoch : 698 - cost: 0.68900925 - MSE: 0.4668397528464577 -Train Accuracy: 0.54545456\n",
      "epoch : 699 - cost: 0.6890095 - MSE: 0.46683976033450764 -Train Accuracy: 0.54545456\n",
      "epoch : 700 - cost: 0.68900925 - MSE: 0.4668397569280345 -Train Accuracy: 0.54545456\n",
      "epoch : 701 - cost: 0.6890095 - MSE: 0.46683976441608455 -Train Accuracy: 0.54545456\n",
      "epoch : 702 - cost: 0.68900925 - MSE: 0.4668397610096112 -Train Accuracy: 0.54545456\n",
      "epoch : 703 - cost: 0.68900925 - MSE: 0.4668397684976612 -Train Accuracy: 0.54545456\n",
      "epoch : 704 - cost: 0.6890095 - MSE: 0.46683977598571164 -Train Accuracy: 0.54545456\n",
      "epoch : 705 - cost: 0.68900925 - MSE: 0.46683977257923814 -Train Accuracy: 0.54545456\n",
      "epoch : 706 - cost: 0.68900925 - MSE: 0.46683978006728855 -Train Accuracy: 0.54545456\n",
      "epoch : 707 - cost: 0.6890095 - MSE: 0.4668397875553391 -Train Accuracy: 0.54545456\n",
      "epoch : 708 - cost: 0.68900925 - MSE: 0.4668397841488655 -Train Accuracy: 0.54545456\n",
      "epoch : 709 - cost: 0.6890095 - MSE: 0.4668397916369161 -Train Accuracy: 0.54545456\n",
      "epoch : 710 - cost: 0.68900925 - MSE: 0.4668397882304425 -Train Accuracy: 0.54545456\n",
      "epoch : 711 - cost: 0.68900925 - MSE: 0.46683979571849316 -Train Accuracy: 0.54545456\n",
      "epoch : 712 - cost: 0.6890095 - MSE: 0.4668398032065441 -Train Accuracy: 0.54545456\n",
      "epoch : 713 - cost: 0.68900925 - MSE: 0.46683979980007023 -Train Accuracy: 0.54545456\n",
      "epoch : 714 - cost: 0.68900925 - MSE: 0.4668398072881212 -Train Accuracy: 0.54545456\n",
      "epoch : 715 - cost: 0.6890095 - MSE: 0.46683981477617226 -Train Accuracy: 0.54545456\n",
      "epoch : 716 - cost: 0.68900925 - MSE: 0.46683981136969827 -Train Accuracy: 0.54545456\n",
      "epoch : 717 - cost: 0.6890095 - MSE: 0.4668398188577495 -Train Accuracy: 0.54545456\n",
      "epoch : 718 - cost: 0.68900925 - MSE: 0.46683981545127556 -Train Accuracy: 0.54545456\n",
      "epoch : 719 - cost: 0.68900925 - MSE: 0.46683982293932674 -Train Accuracy: 0.54545456\n",
      "epoch : 720 - cost: 0.6890095 - MSE: 0.46683983042737837 -Train Accuracy: 0.54545456\n",
      "epoch : 721 - cost: 0.68900925 - MSE: 0.4668398270209042 -Train Accuracy: 0.54545456\n",
      "epoch : 722 - cost: 0.68900925 - MSE: 0.4668398345089557 -Train Accuracy: 0.54545456\n",
      "epoch : 723 - cost: 0.6890095 - MSE: 0.4668398419970073 -Train Accuracy: 0.54545456\n",
      "epoch : 724 - cost: 0.68900925 - MSE: 0.466839838590533 -Train Accuracy: 0.54545456\n",
      "epoch : 725 - cost: 0.6890095 - MSE: 0.46683984607858486 -Train Accuracy: 0.54545456\n",
      "epoch : 726 - cost: 0.68900925 - MSE: 0.4668398426721107 -Train Accuracy: 0.54545456\n",
      "epoch : 727 - cost: 0.68900925 - MSE: 0.4668398501601623 -Train Accuracy: 0.54545456\n",
      "epoch : 728 - cost: 0.6890095 - MSE: 0.46683985764821434 -Train Accuracy: 0.54545456\n",
      "epoch : 729 - cost: 0.68900925 - MSE: 0.46683985424173985 -Train Accuracy: 0.54545456\n",
      "epoch : 730 - cost: 0.68900925 - MSE: 0.466839861729792 -Train Accuracy: 0.54545456\n",
      "epoch : 731 - cost: 0.6890095 - MSE: 0.4668398692178441 -Train Accuracy: 0.54545456\n",
      "epoch : 732 - cost: 0.68900925 - MSE: 0.4668398658113695 -Train Accuracy: 0.54545456\n",
      "epoch : 733 - cost: 0.6890095 - MSE: 0.4668398732994219 -Train Accuracy: 0.54545456\n",
      "epoch : 734 - cost: 0.68900925 - MSE: 0.4668398698929471 -Train Accuracy: 0.54545456\n",
      "epoch : 735 - cost: 0.68900925 - MSE: 0.4668398773809993 -Train Accuracy: 0.54545456\n",
      "epoch : 736 - cost: 0.6890095 - MSE: 0.46683988486905226 -Train Accuracy: 0.54545456\n",
      "epoch : 737 - cost: 0.68900925 - MSE: 0.4668398814625772 -Train Accuracy: 0.54545456\n",
      "epoch : 738 - cost: 0.68900925 - MSE: 0.46683988895063 -Train Accuracy: 0.54545456\n",
      "epoch : 739 - cost: 0.6890095 - MSE: 0.4668398964386827 -Train Accuracy: 0.54545456\n",
      "epoch : 740 - cost: 0.68900925 - MSE: 0.4668398930322078 -Train Accuracy: 0.54545456\n",
      "epoch : 741 - cost: 0.6890095 - MSE: 0.4668399005202606 -Train Accuracy: 0.54545456\n",
      "epoch : 742 - cost: 0.68900925 - MSE: 0.4668398971137858 -Train Accuracy: 0.54545456\n",
      "epoch : 743 - cost: 0.68900925 - MSE: 0.46683990460183855 -Train Accuracy: 0.54545456\n",
      "epoch : 744 - cost: 0.6890095 - MSE: 0.4668399120898917 -Train Accuracy: 0.54545456\n",
      "epoch : 745 - cost: 0.68900925 - MSE: 0.46683990868341646 -Train Accuracy: 0.54545456\n",
      "epoch : 746 - cost: 0.68900925 - MSE: 0.46683991617146975 -Train Accuracy: 0.54545456\n",
      "epoch : 747 - cost: 0.6890095 - MSE: 0.46683992365952304 -Train Accuracy: 0.54545456\n",
      "epoch : 748 - cost: 0.68900925 - MSE: 0.4668399202530478 -Train Accuracy: 0.54545456\n",
      "epoch : 749 - cost: 0.6890095 - MSE: 0.4668399277411011 -Train Accuracy: 0.54545456\n",
      "epoch : 750 - cost: 0.68900925 - MSE: 0.4668399243346259 -Train Accuracy: 0.54545456\n",
      "epoch : 751 - cost: 0.68900925 - MSE: 0.4668399318226792 -Train Accuracy: 0.54545456\n",
      "epoch : 752 - cost: 0.6890095 - MSE: 0.46683993931073303 -Train Accuracy: 0.54545456\n",
      "epoch : 753 - cost: 0.68900925 - MSE: 0.4668399359042576 -Train Accuracy: 0.54545456\n",
      "epoch : 754 - cost: 0.68900925 - MSE: 0.4668399433923112 -Train Accuracy: 0.54545456\n",
      "epoch : 755 - cost: 0.6890095 - MSE: 0.46683995088036506 -Train Accuracy: 0.54545456\n",
      "epoch : 756 - cost: 0.68900925 - MSE: 0.4668399474738896 -Train Accuracy: 0.54545456\n",
      "epoch : 757 - cost: 0.6890095 - MSE: 0.4668399549619434 -Train Accuracy: 0.54545456\n",
      "epoch : 758 - cost: 0.68900925 - MSE: 0.46683995155546787 -Train Accuracy: 0.54545456\n",
      "epoch : 759 - cost: 0.68900925 - MSE: 0.4668399590435218 -Train Accuracy: 0.54545456\n",
      "epoch : 760 - cost: 0.6890095 - MSE: 0.4668399665315763 -Train Accuracy: 0.54545456\n",
      "epoch : 761 - cost: 0.68900925 - MSE: 0.4668399631251004 -Train Accuracy: 0.54545456\n",
      "epoch : 762 - cost: 0.68900925 - MSE: 0.4668399706131545 -Train Accuracy: 0.54545456\n",
      "epoch : 763 - cost: 0.6890095 - MSE: 0.466839978101209 -Train Accuracy: 0.54545456\n",
      "epoch : 764 - cost: 0.68900925 - MSE: 0.4668399746947331 -Train Accuracy: 0.54545456\n",
      "epoch : 765 - cost: 0.6890095 - MSE: 0.4668399821827877 -Train Accuracy: 0.54545456\n",
      "epoch : 766 - cost: 0.68900925 - MSE: 0.46683997877631167 -Train Accuracy: 0.54545456\n",
      "epoch : 767 - cost: 0.68900925 - MSE: 0.46683998626436607 -Train Accuracy: 0.54545456\n",
      "epoch : 768 - cost: 0.6890095 - MSE: 0.4668399937524209 -Train Accuracy: 0.54545456\n",
      "epoch : 769 - cost: 0.68900925 - MSE: 0.46683999034594476 -Train Accuracy: 0.54545456\n",
      "epoch : 770 - cost: 0.68900925 - MSE: 0.4668399978339997 -Train Accuracy: 0.54545456\n",
      "epoch : 771 - cost: 0.6890095 - MSE: 0.46684000532205466 -Train Accuracy: 0.54545456\n",
      "epoch : 772 - cost: 0.68900925 - MSE: 0.46684000191557845 -Train Accuracy: 0.54545456\n",
      "epoch : 773 - cost: 0.6890095 - MSE: 0.4668400094036334 -Train Accuracy: 0.54545456\n",
      "epoch : 774 - cost: 0.68900925 - MSE: 0.4668400059971572 -Train Accuracy: 0.54545456\n",
      "epoch : 775 - cost: 0.68900925 - MSE: 0.46684001348521226 -Train Accuracy: 0.54545456\n",
      "epoch : 776 - cost: 0.6890095 - MSE: 0.46684002097326766 -Train Accuracy: 0.54545456\n",
      "epoch : 777 - cost: 0.68900925 - MSE: 0.4668400175667911 -Train Accuracy: 0.54545456\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch : 778 - cost: 0.68900925 - MSE: 0.46684002505484656 -Train Accuracy: 0.54545456\n",
      "epoch : 779 - cost: 0.6890095 - MSE: 0.466840032542902 -Train Accuracy: 0.54545456\n",
      "epoch : 780 - cost: 0.68900925 - MSE: 0.4668400291364254 -Train Accuracy: 0.54545456\n",
      "epoch : 781 - cost: 0.6890095 - MSE: 0.46684003662448104 -Train Accuracy: 0.54545456\n",
      "epoch : 782 - cost: 0.68900925 - MSE: 0.46684003321800444 -Train Accuracy: 0.54545456\n",
      "epoch : 783 - cost: 0.68900925 - MSE: 0.46684004070606006 -Train Accuracy: 0.54545456\n",
      "epoch : 784 - cost: 0.6890095 - MSE: 0.4668400481941162 -Train Accuracy: 0.54545456\n",
      "epoch : 785 - cost: 0.68900925 - MSE: 0.4668400447876393 -Train Accuracy: 0.54545456\n",
      "epoch : 786 - cost: 0.68900925 - MSE: 0.4668400522756953 -Train Accuracy: 0.54545456\n",
      "epoch : 787 - cost: 0.6890095 - MSE: 0.46684005976375126 -Train Accuracy: 0.54545456\n",
      "epoch : 788 - cost: 0.68900925 - MSE: 0.4668400563572744 -Train Accuracy: 0.54545456\n",
      "epoch : 789 - cost: 0.6890095 - MSE: 0.4668400638453307 -Train Accuracy: 0.54545456\n",
      "epoch : 790 - cost: 0.68900925 - MSE: 0.46684006043885373 -Train Accuracy: 0.54545456\n",
      "epoch : 791 - cost: 0.68900925 - MSE: 0.4668400679269098 -Train Accuracy: 0.54545456\n",
      "epoch : 792 - cost: 0.6890095 - MSE: 0.4668400754149663 -Train Accuracy: 0.54545456\n",
      "epoch : 793 - cost: 0.68900925 - MSE: 0.46684007200848904 -Train Accuracy: 0.54545456\n",
      "epoch : 794 - cost: 0.68900925 - MSE: 0.4668400794965457 -Train Accuracy: 0.54545456\n",
      "epoch : 795 - cost: 0.6890095 - MSE: 0.4668400869846023 -Train Accuracy: 0.54545456\n",
      "epoch : 796 - cost: 0.68900925 - MSE: 0.46684008357812495 -Train Accuracy: 0.54545456\n",
      "epoch : 797 - cost: 0.6890095 - MSE: 0.4668400910661818 -Train Accuracy: 0.54545456\n",
      "epoch : 798 - cost: 0.68900925 - MSE: 0.4668400876597044 -Train Accuracy: 0.54545456\n",
      "epoch : 799 - cost: 0.68900925 - MSE: 0.46684009514776104 -Train Accuracy: 0.54545456\n",
      "epoch : 800 - cost: 0.6890095 - MSE: 0.4668401026358184 -Train Accuracy: 0.54545456\n",
      "epoch : 801 - cost: 0.68900925 - MSE: 0.46684009922934067 -Train Accuracy: 0.54545456\n",
      "epoch : 802 - cost: 0.68900925 - MSE: 0.466840106717398 -Train Accuracy: 0.54545456\n",
      "epoch : 803 - cost: 0.6890095 - MSE: 0.46684011420545507 -Train Accuracy: 0.54545456\n",
      "epoch : 804 - cost: 0.68900925 - MSE: 0.4668401107989776 -Train Accuracy: 0.54545456\n",
      "epoch : 805 - cost: 0.6890095 - MSE: 0.46684011828703476 -Train Accuracy: 0.54545456\n",
      "epoch : 806 - cost: 0.68900925 - MSE: 0.4668401148805572 -Train Accuracy: 0.54545456\n",
      "epoch : 807 - cost: 0.68900925 - MSE: 0.46684012236861455 -Train Accuracy: 0.54545456\n",
      "epoch : 808 - cost: 0.6890095 - MSE: 0.46684012985667217 -Train Accuracy: 0.54545456\n",
      "epoch : 809 - cost: 0.68900925 - MSE: 0.46684012645019424 -Train Accuracy: 0.54545456\n",
      "epoch : 810 - cost: 0.68900925 - MSE: 0.46684013393825186 -Train Accuracy: 0.54545456\n",
      "epoch : 811 - cost: 0.6890095 - MSE: 0.46684014142630964 -Train Accuracy: 0.54545456\n",
      "epoch : 812 - cost: 0.68900925 - MSE: 0.46684013801983176 -Train Accuracy: 0.54545456\n",
      "epoch : 813 - cost: 0.6890095 - MSE: 0.4668401455078894 -Train Accuracy: 0.54545456\n",
      "epoch : 814 - cost: 0.68900925 - MSE: 0.46684014210141167 -Train Accuracy: 0.54545456\n",
      "epoch : 815 - cost: 0.68900925 - MSE: 0.46684014958946934 -Train Accuracy: 0.54545456\n",
      "epoch : 816 - cost: 0.6890095 - MSE: 0.46684015707752763 -Train Accuracy: 0.54545456\n",
      "epoch : 817 - cost: 0.68900925 - MSE: 0.4668401536710495 -Train Accuracy: 0.54545456\n",
      "epoch : 818 - cost: 0.68900925 - MSE: 0.4668401611591077 -Train Accuracy: 0.54545456\n",
      "epoch : 819 - cost: 0.6890095 - MSE: 0.4668401686471659 -Train Accuracy: 0.54545456\n",
      "epoch : 820 - cost: 0.68900925 - MSE: 0.46684016524068783 -Train Accuracy: 0.54545456\n",
      "epoch : 821 - cost: 0.6890095 - MSE: 0.46684017272874606 -Train Accuracy: 0.54545456\n",
      "epoch : 822 - cost: 0.68900925 - MSE: 0.46684016932226785 -Train Accuracy: 0.54545456\n",
      "epoch : 823 - cost: 0.68900925 - MSE: 0.4668401768103262 -Train Accuracy: 0.54545456\n",
      "epoch : 824 - cost: 0.6890095 - MSE: 0.46684018429838503 -Train Accuracy: 0.54545456\n",
      "epoch : 825 - cost: 0.68900925 - MSE: 0.4668401808919065 -Train Accuracy: 0.54545456\n",
      "epoch : 826 - cost: 0.68900925 - MSE: 0.46684018837996516 -Train Accuracy: 0.54545456\n",
      "epoch : 827 - cost: 0.6890095 - MSE: 0.466840195868024 -Train Accuracy: 0.54545456\n",
      "epoch : 828 - cost: 0.68900925 - MSE: 0.4668401924615455 -Train Accuracy: 0.54545456\n",
      "epoch : 829 - cost: 0.6890095 - MSE: 0.46684019994960446 -Train Accuracy: 0.54545456\n",
      "epoch : 830 - cost: 0.68900925 - MSE: 0.46684019654312586 -Train Accuracy: 0.54545456\n",
      "epoch : 831 - cost: 0.68900925 - MSE: 0.46684020403118465 -Train Accuracy: 0.54545456\n",
      "epoch : 832 - cost: 0.6890095 - MSE: 0.4668402115192441 -Train Accuracy: 0.54545456\n",
      "epoch : 833 - cost: 0.68900925 - MSE: 0.46684020811276516 -Train Accuracy: 0.54545456\n",
      "epoch : 834 - cost: 0.68900925 - MSE: 0.4668402156008244 -Train Accuracy: 0.54545456\n",
      "epoch : 835 - cost: 0.6890095 - MSE: 0.4668402230888839 -Train Accuracy: 0.54545456\n",
      "epoch : 836 - cost: 0.68900925 - MSE: 0.46684021968240497 -Train Accuracy: 0.54545456\n",
      "epoch : 837 - cost: 0.6890095 - MSE: 0.4668402271704644 -Train Accuracy: 0.54545456\n",
      "epoch : 838 - cost: 0.68900925 - MSE: 0.4668402237639856 -Train Accuracy: 0.54545456\n",
      "epoch : 839 - cost: 0.68900925 - MSE: 0.46684023125204505 -Train Accuracy: 0.54545456\n",
      "epoch : 840 - cost: 0.6890095 - MSE: 0.46684023874010483 -Train Accuracy: 0.54545456\n",
      "epoch : 841 - cost: 0.68900925 - MSE: 0.4668402353336257 -Train Accuracy: 0.54545456\n",
      "epoch : 842 - cost: 0.68900925 - MSE: 0.4668402428216855 -Train Accuracy: 0.54545456\n",
      "epoch : 843 - cost: 0.6890095 - MSE: 0.46684025030974546 -Train Accuracy: 0.54545456\n",
      "epoch : 844 - cost: 0.68900925 - MSE: 0.46684024690326625 -Train Accuracy: 0.54545456\n",
      "epoch : 845 - cost: 0.6890095 - MSE: 0.46684025439132626 -Train Accuracy: 0.54545456\n",
      "epoch : 846 - cost: 0.68900925 - MSE: 0.46684025098484705 -Train Accuracy: 0.54545456\n",
      "epoch : 847 - cost: 0.68900925 - MSE: 0.46684025847290705 -Train Accuracy: 0.54545456\n",
      "epoch : 848 - cost: 0.6890095 - MSE: 0.4668402659609676 -Train Accuracy: 0.54545456\n",
      "epoch : 849 - cost: 0.68900925 - MSE: 0.46684026255448813 -Train Accuracy: 0.54545456\n",
      "epoch : 850 - cost: 0.68900925 - MSE: 0.46684027004254847 -Train Accuracy: 0.54545456\n",
      "epoch : 851 - cost: 0.6890095 - MSE: 0.4668402775306089 -Train Accuracy: 0.54545456\n",
      "epoch : 852 - cost: 0.68900925 - MSE: 0.4668402741241294 -Train Accuracy: 0.54545456\n",
      "epoch : 853 - cost: 0.6890095 - MSE: 0.46684028161219004 -Train Accuracy: 0.54545456\n",
      "epoch : 854 - cost: 0.68900925 - MSE: 0.46684027820571056 -Train Accuracy: 0.54545456\n",
      "epoch : 855 - cost: 0.68900925 - MSE: 0.466840285693771 -Train Accuracy: 0.54545456\n",
      "epoch : 856 - cost: 0.6890095 - MSE: 0.4668402931818319 -Train Accuracy: 0.54545456\n",
      "epoch : 857 - cost: 0.68900925 - MSE: 0.46684028977535214 -Train Accuracy: 0.54545456\n",
      "epoch : 858 - cost: 0.68900925 - MSE: 0.4668402972634132 -Train Accuracy: 0.54545456\n",
      "epoch : 859 - cost: 0.6890095 - MSE: 0.46684030475147414 -Train Accuracy: 0.54545456\n",
      "epoch : 860 - cost: 0.68900925 - MSE: 0.4668403013449943 -Train Accuracy: 0.54545456\n",
      "epoch : 861 - cost: 0.6890095 - MSE: 0.46684030883305555 -Train Accuracy: 0.54545456\n",
      "epoch : 862 - cost: 0.68900925 - MSE: 0.46684030542657545 -Train Accuracy: 0.54545456\n",
      "epoch : 863 - cost: 0.68900925 - MSE: 0.4668403129146365 -Train Accuracy: 0.54545456\n",
      "epoch : 864 - cost: 0.6890095 - MSE: 0.4668403204026983 -Train Accuracy: 0.54545456\n",
      "epoch : 865 - cost: 0.68900925 - MSE: 0.466840316996218 -Train Accuracy: 0.54545456\n",
      "epoch : 866 - cost: 0.68900925 - MSE: 0.4668403244842796 -Train Accuracy: 0.54545456\n",
      "epoch : 867 - cost: 0.6890095 - MSE: 0.46684033197234115 -Train Accuracy: 0.54545456\n",
      "epoch : 868 - cost: 0.68900925 - MSE: 0.466840328565861 -Train Accuracy: 0.54545456\n",
      "epoch : 869 - cost: 0.6890095 - MSE: 0.4668403360539226 -Train Accuracy: 0.54545456\n",
      "epoch : 870 - cost: 0.68900925 - MSE: 0.46684033264744246 -Train Accuracy: 0.54545456\n",
      "epoch : 871 - cost: 0.68900925 - MSE: 0.4668403401355042 -Train Accuracy: 0.54545456\n",
      "epoch : 872 - cost: 0.6890095 - MSE: 0.46684034762356613 -Train Accuracy: 0.54545456\n",
      "epoch : 873 - cost: 0.68900925 - MSE: 0.46684034421708565 -Train Accuracy: 0.54545456\n",
      "epoch : 874 - cost: 0.68900925 - MSE: 0.46684035170514776 -Train Accuracy: 0.54545456\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch : 875 - cost: 0.6890095 - MSE: 0.46684035919320993 -Train Accuracy: 0.54545456\n",
      "epoch : 876 - cost: 0.68900925 - MSE: 0.46684035578672933 -Train Accuracy: 0.54545456\n",
      "epoch : 877 - cost: 0.6890095 - MSE: 0.46684036327479156 -Train Accuracy: 0.54545456\n",
      "epoch : 878 - cost: 0.68900925 - MSE: 0.46684035986831107 -Train Accuracy: 0.54545456\n",
      "epoch : 879 - cost: 0.68900925 - MSE: 0.4668403673563732 -Train Accuracy: 0.54545456\n",
      "epoch : 880 - cost: 0.6890095 - MSE: 0.46684037484443597 -Train Accuracy: 0.54545456\n",
      "epoch : 881 - cost: 0.68900925 - MSE: 0.46684037143795515 -Train Accuracy: 0.54545456\n",
      "epoch : 882 - cost: 0.68900925 - MSE: 0.46684037892601765 -Train Accuracy: 0.54545456\n",
      "epoch : 883 - cost: 0.6890095 - MSE: 0.4668403864140804 -Train Accuracy: 0.54545456\n",
      "epoch : 884 - cost: 0.68900925 - MSE: 0.4668403830075997 -Train Accuracy: 0.54545456\n",
      "epoch : 885 - cost: 0.6890095 - MSE: 0.4668403904956623 -Train Accuracy: 0.54545456\n",
      "epoch : 886 - cost: 0.68900925 - MSE: 0.4668403870891814 -Train Accuracy: 0.54545456\n",
      "epoch : 887 - cost: 0.68900925 - MSE: 0.46684039457724424 -Train Accuracy: 0.54545456\n",
      "epoch : 888 - cost: 0.6890095 - MSE: 0.4668404020653075 -Train Accuracy: 0.54545456\n",
      "epoch : 889 - cost: 0.68900925 - MSE: 0.4668403986588264 -Train Accuracy: 0.54545456\n",
      "epoch : 890 - cost: 0.68900925 - MSE: 0.4668404061468894 -Train Accuracy: 0.54545456\n",
      "epoch : 891 - cost: 0.6890095 - MSE: 0.4668404136349527 -Train Accuracy: 0.54545456\n",
      "epoch : 892 - cost: 0.68900925 - MSE: 0.46684041022847156 -Train Accuracy: 0.54545456\n",
      "epoch : 893 - cost: 0.6890095 - MSE: 0.46684041771653506 -Train Accuracy: 0.54545456\n",
      "epoch : 894 - cost: 0.68900925 - MSE: 0.4668404143100537 -Train Accuracy: 0.54545456\n",
      "epoch : 895 - cost: 0.68900925 - MSE: 0.4668404217981169 -Train Accuracy: 0.54545456\n",
      "epoch : 896 - cost: 0.6890095 - MSE: 0.46684042928618075 -Train Accuracy: 0.54545456\n",
      "epoch : 897 - cost: 0.68900925 - MSE: 0.46684042587969915 -Train Accuracy: 0.54545456\n",
      "epoch : 898 - cost: 0.68900925 - MSE: 0.46684043336776293 -Train Accuracy: 0.54545456\n",
      "epoch : 899 - cost: 0.6890095 - MSE: 0.4668404408558268 -Train Accuracy: 0.54545456\n",
      "epoch : 900 - cost: 0.68900925 - MSE: 0.4668404374493452 -Train Accuracy: 0.54545456\n",
      "epoch : 901 - cost: 0.6890095 - MSE: 0.46684044493740917 -Train Accuracy: 0.54545456\n",
      "epoch : 902 - cost: 0.68900925 - MSE: 0.46684044153092763 -Train Accuracy: 0.54545456\n",
      "epoch : 903 - cost: 0.68900925 - MSE: 0.4668404490189915 -Train Accuracy: 0.54545456\n",
      "epoch : 904 - cost: 0.6890095 - MSE: 0.4668404565070558 -Train Accuracy: 0.54545456\n",
      "epoch : 905 - cost: 0.68900925 - MSE: 0.4668404531005739 -Train Accuracy: 0.54545456\n",
      "epoch : 906 - cost: 0.68900925 - MSE: 0.4668404605886382 -Train Accuracy: 0.54545456\n",
      "epoch : 907 - cost: 0.6890095 - MSE: 0.46684046807670265 -Train Accuracy: 0.54545456\n",
      "epoch : 908 - cost: 0.68900925 - MSE: 0.46684046467022067 -Train Accuracy: 0.54545456\n",
      "epoch : 909 - cost: 0.6890095 - MSE: 0.46684047215828517 -Train Accuracy: 0.54545456\n",
      "epoch : 910 - cost: 0.68900925 - MSE: 0.46684046875180335 -Train Accuracy: 0.54545456\n",
      "epoch : 911 - cost: 0.68900925 - MSE: 0.46684047623986774 -Train Accuracy: 0.54545456\n",
      "epoch : 912 - cost: 0.6890095 - MSE: 0.4668404837279328 -Train Accuracy: 0.54545456\n",
      "epoch : 913 - cost: 0.68900925 - MSE: 0.4668404803214506 -Train Accuracy: 0.54545456\n",
      "epoch : 914 - cost: 0.68900925 - MSE: 0.4668404878095154 -Train Accuracy: 0.54545456\n",
      "epoch : 915 - cost: 0.6890095 - MSE: 0.4668404952975803 -Train Accuracy: 0.54545456\n",
      "epoch : 916 - cost: 0.68900925 - MSE: 0.4668404918910981 -Train Accuracy: 0.54545456\n",
      "epoch : 917 - cost: 0.6890095 - MSE: 0.4668404993791633 -Train Accuracy: 0.54545456\n",
      "epoch : 918 - cost: 0.68900925 - MSE: 0.46684049597268096 -Train Accuracy: 0.54545456\n",
      "epoch : 919 - cost: 0.68900925 - MSE: 0.4668405034607459 -Train Accuracy: 0.54545456\n",
      "epoch : 920 - cost: 0.6890095 - MSE: 0.46684051094881135 -Train Accuracy: 0.54545456\n",
      "epoch : 921 - cost: 0.68900925 - MSE: 0.46684050754232875 -Train Accuracy: 0.54545456\n",
      "epoch : 922 - cost: 0.68900925 - MSE: 0.46684051503039437 -Train Accuracy: 0.54545456\n",
      "epoch : 923 - cost: 0.6890095 - MSE: 0.4668405225184597 -Train Accuracy: 0.54545456\n",
      "epoch : 924 - cost: 0.68900925 - MSE: 0.4668405191119771 -Train Accuracy: 0.54545456\n",
      "epoch : 925 - cost: 0.6890095 - MSE: 0.46684052660004277 -Train Accuracy: 0.54545456\n",
      "epoch : 926 - cost: 0.68900925 - MSE: 0.4668405231935602 -Train Accuracy: 0.54545456\n",
      "epoch : 927 - cost: 0.68900925 - MSE: 0.4668405306816256 -Train Accuracy: 0.54545456\n",
      "epoch : 928 - cost: 0.6890095 - MSE: 0.46684053816969184 -Train Accuracy: 0.54545456\n",
      "epoch : 929 - cost: 0.68900925 - MSE: 0.46684053476320875 -Train Accuracy: 0.54545456\n",
      "epoch : 930 - cost: 0.68900925 - MSE: 0.46684054225127497 -Train Accuracy: 0.54545456\n",
      "epoch : 931 - cost: 0.6890095 - MSE: 0.4668405497393409 -Train Accuracy: 0.54545456\n",
      "epoch : 932 - cost: 0.68900925 - MSE: 0.46684054633285815 -Train Accuracy: 0.54545456\n",
      "epoch : 933 - cost: 0.6890095 - MSE: 0.46684055382092415 -Train Accuracy: 0.54545456\n",
      "epoch : 934 - cost: 0.68900925 - MSE: 0.4668405504144413 -Train Accuracy: 0.54545456\n",
      "epoch : 935 - cost: 0.68900925 - MSE: 0.4668405579025075 -Train Accuracy: 0.54545456\n",
      "epoch : 936 - cost: 0.6890095 - MSE: 0.46684056539057395 -Train Accuracy: 0.54545456\n",
      "epoch : 937 - cost: 0.68900925 - MSE: 0.46684056198409074 -Train Accuracy: 0.54545456\n",
      "epoch : 938 - cost: 0.68900925 - MSE: 0.4668405694721573 -Train Accuracy: 0.54545456\n",
      "epoch : 939 - cost: 0.6890095 - MSE: 0.4668405769602239 -Train Accuracy: 0.54545456\n",
      "epoch : 940 - cost: 0.68900925 - MSE: 0.4668405735537407 -Train Accuracy: 0.54545456\n",
      "epoch : 941 - cost: 0.6890095 - MSE: 0.46684058104180726 -Train Accuracy: 0.54545456\n",
      "epoch : 942 - cost: 0.68900925 - MSE: 0.4668405776353241 -Train Accuracy: 0.54545456\n",
      "epoch : 943 - cost: 0.68900925 - MSE: 0.4668405851233907 -Train Accuracy: 0.54545456\n",
      "epoch : 944 - cost: 0.6890095 - MSE: 0.4668405926114579 -Train Accuracy: 0.54545456\n",
      "epoch : 945 - cost: 0.68900925 - MSE: 0.4668405892049744 -Train Accuracy: 0.54545456\n",
      "epoch : 946 - cost: 0.68900925 - MSE: 0.46684059669304157 -Train Accuracy: 0.54545456\n",
      "epoch : 947 - cost: 0.6890095 - MSE: 0.4668406041811086 -Train Accuracy: 0.54545456\n",
      "epoch : 948 - cost: 0.68900925 - MSE: 0.4668406007746252 -Train Accuracy: 0.54545456\n",
      "epoch : 949 - cost: 0.6890095 - MSE: 0.46684060826269236 -Train Accuracy: 0.54545456\n",
      "epoch : 950 - cost: 0.68900925 - MSE: 0.46684060485620876 -Train Accuracy: 0.54545456\n",
      "epoch : 951 - cost: 0.68900925 - MSE: 0.466840612344276 -Train Accuracy: 0.54545456\n",
      "epoch : 952 - cost: 0.6890095 - MSE: 0.46684061983234376 -Train Accuracy: 0.54545456\n",
      "epoch : 953 - cost: 0.68900925 - MSE: 0.46684061642585983 -Train Accuracy: 0.54545456\n",
      "epoch : 954 - cost: 0.68900925 - MSE: 0.4668406239139274 -Train Accuracy: 0.54545456\n",
      "epoch : 955 - cost: 0.6890095 - MSE: 0.46684063140199517 -Train Accuracy: 0.54545456\n",
      "epoch : 956 - cost: 0.68900925 - MSE: 0.46684062799551135 -Train Accuracy: 0.54545456\n",
      "epoch : 957 - cost: 0.6890095 - MSE: 0.4668406354835791 -Train Accuracy: 0.54545456\n",
      "epoch : 958 - cost: 0.68900925 - MSE: 0.46684063207709514 -Train Accuracy: 0.54545456\n",
      "epoch : 959 - cost: 0.68900925 - MSE: 0.46684063956516286 -Train Accuracy: 0.54545456\n",
      "epoch : 960 - cost: 0.6890095 - MSE: 0.46684064705323114 -Train Accuracy: 0.54545456\n",
      "epoch : 961 - cost: 0.68900925 - MSE: 0.466840643646747 -Train Accuracy: 0.54545456\n",
      "epoch : 962 - cost: 0.68900925 - MSE: 0.46684065113481515 -Train Accuracy: 0.54545456\n",
      "epoch : 963 - cost: 0.6890095 - MSE: 0.46684065862288343 -Train Accuracy: 0.54545456\n",
      "epoch : 964 - cost: 0.68900925 - MSE: 0.4668406552163992 -Train Accuracy: 0.54545456\n",
      "epoch : 965 - cost: 0.6890095 - MSE: 0.46684066270446756 -Train Accuracy: 0.54545456\n",
      "epoch : 966 - cost: 0.68900925 - MSE: 0.4668406592979833 -Train Accuracy: 0.54545456\n",
      "epoch : 967 - cost: 0.68900925 - MSE: 0.46684066678605174 -Train Accuracy: 0.54545456\n",
      "epoch : 968 - cost: 0.6890095 - MSE: 0.46684067427412046 -Train Accuracy: 0.54545456\n",
      "epoch : 969 - cost: 0.68900925 - MSE: 0.46684067086763587 -Train Accuracy: 0.54545456\n",
      "epoch : 970 - cost: 0.68900925 - MSE: 0.46684067835570464 -Train Accuracy: 0.54545456\n",
      "epoch : 971 - cost: 0.6890095 - MSE: 0.4668406858437735 -Train Accuracy: 0.54545456\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch : 972 - cost: 0.68900925 - MSE: 0.4668406824372888 -Train Accuracy: 0.54545456\n",
      "epoch : 973 - cost: 0.6890095 - MSE: 0.4668406899253578 -Train Accuracy: 0.54545456\n",
      "epoch : 974 - cost: 0.68900925 - MSE: 0.4668406865188732 -Train Accuracy: 0.54545456\n",
      "epoch : 975 - cost: 0.68900925 - MSE: 0.46684069400694217 -Train Accuracy: 0.54545456\n",
      "epoch : 976 - cost: 0.6890095 - MSE: 0.46684070149501156 -Train Accuracy: 0.54545456\n",
      "epoch : 977 - cost: 0.68900925 - MSE: 0.46684069808852674 -Train Accuracy: 0.54545456\n",
      "epoch : 978 - cost: 0.68900925 - MSE: 0.466840705576596 -Train Accuracy: 0.54545456\n",
      "epoch : 979 - cost: 0.6890095 - MSE: 0.46684071306466535 -Train Accuracy: 0.54545456\n",
      "epoch : 980 - cost: 0.68900925 - MSE: 0.4668407096581804 -Train Accuracy: 0.54545456\n",
      "epoch : 981 - cost: 0.6890095 - MSE: 0.46684071714625003 -Train Accuracy: 0.54545456\n",
      "epoch : 982 - cost: 0.68900925 - MSE: 0.46684071373976516 -Train Accuracy: 0.54545456\n",
      "epoch : 983 - cost: 0.68900925 - MSE: 0.46684072122783454 -Train Accuracy: 0.54545456\n",
      "epoch : 984 - cost: 0.6890095 - MSE: 0.4668407287159044 -Train Accuracy: 0.54545456\n",
      "epoch : 985 - cost: 0.68900925 - MSE: 0.4668407253094192 -Train Accuracy: 0.54545456\n",
      "epoch : 986 - cost: 0.68900925 - MSE: 0.4668407327974891 -Train Accuracy: 0.54545456\n",
      "epoch : 987 - cost: 0.6890095 - MSE: 0.466840740285559 -Train Accuracy: 0.54545456\n",
      "epoch : 988 - cost: 0.68900925 - MSE: 0.46684073687907374 -Train Accuracy: 0.54545456\n",
      "epoch : 989 - cost: 0.6890095 - MSE: 0.4668407443671439 -Train Accuracy: 0.54545456\n",
      "epoch : 990 - cost: 0.68900925 - MSE: 0.4668407409606585 -Train Accuracy: 0.54545456\n",
      "epoch : 991 - cost: 0.68900925 - MSE: 0.4668407484487284 -Train Accuracy: 0.54545456\n",
      "epoch : 992 - cost: 0.6890095 - MSE: 0.46684075593679913 -Train Accuracy: 0.54545456\n",
      "epoch : 993 - cost: 0.68900925 - MSE: 0.46684075253031343 -Train Accuracy: 0.54545456\n",
      "epoch : 994 - cost: 0.68900925 - MSE: 0.466840760018384 -Train Accuracy: 0.54545456\n",
      "epoch : 995 - cost: 0.6890095 - MSE: 0.4668407675064544 -Train Accuracy: 0.54545456\n",
      "epoch : 996 - cost: 0.68900925 - MSE: 0.4668407640999689 -Train Accuracy: 0.54545456\n",
      "epoch : 997 - cost: 0.6890095 - MSE: 0.46684077158803944 -Train Accuracy: 0.54545456\n",
      "epoch : 998 - cost: 0.68900925 - MSE: 0.466840768181554 -Train Accuracy: 0.54545456\n",
      "epoch : 999 - cost: 0.68900925 - MSE: 0.4668407756696245 -Train Accuracy: 0.54545456\n",
      "Model saved in file: C:\\Users\\AndyJazz\\PycharmProjects\\Tensorflow\\NMI\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 0.5\n",
      "MSE: 0.4668\n"
     ]
    }
   ],
   "source": [
    "#reading dataset\n",
    "def read_dataset():\n",
    "    df = pd.read_csv('C:/Users/AndyJazz/Desktop/Dataset/rock and mine/sonar.csv')\n",
    "    #print length of the dataset\n",
    "    X = df[df.columns[0:60]].values\n",
    "    y = df[df.columns[60]].values\n",
    "    \n",
    "    #Encoder the dependent variable\n",
    "    encoder = LabelEncoder()\n",
    "    encoder.fit(y)\n",
    "    y = encoder.transform(y)\n",
    "    Y = one_hot_encode(y)\n",
    "    print(X.shape)\n",
    "    return(X, Y)\n",
    "\n",
    "#Define the encoder function.\n",
    "def one_hot_encode(labels):\n",
    "    n_labels = len(labels)\n",
    "    n_unique_labels = len(np.unique(labels))\n",
    "    one_hot_encode = np.zeros((n_labels, n_unique_labels))\n",
    "    one_hot_encode[np.arange(n_labels), labels] = 1\n",
    "    return one_hot_encode\n",
    "\n",
    "#Read the dataset\n",
    "X, Y = read_dataset()\n",
    "\n",
    "#shuffle the dataset to mix up the rows\n",
    "X, Y = shuffle(X, Y, random_state=1)\n",
    "\n",
    "#convert the data into Train and Test\n",
    "train_x, test_x, train_y, test_y, = train_test_split(X, Y, test_size=0.20, random_state=415)\n",
    "\n",
    "#Inspect the shape of the training and testing \n",
    "print(train_x.shape)\n",
    "print(train_y.shape)\n",
    "print(test_x.shape)\n",
    "\n",
    "#Define the important parameters and variable to work with the tensors\n",
    "learning_rate = 0.3\n",
    "training_epochs = 1000 #epoch is the total number of itiration\n",
    "cost_history = np.empty(shape=[1], dtype=float)\n",
    "n_dim = X.shape[1]\n",
    "print(\"n_dim\", n_dim)\n",
    "n_class = 2 #number of output classes which is 'ROCK/MINE'\n",
    "model_path = \"C:\\\\Users\\\\AndyJazz\\\\PycharmProjects\\\\Tensorflow\\\\NMI\"\n",
    "\n",
    "#Define the number of hidden layers and number of neuron for each layer\n",
    "n_hidden_1 = 60\n",
    "n_hidden_2 = 60\n",
    "n_hidden_3 = 60\n",
    "n_hidden_4 = 60\n",
    "\n",
    "x = tf.placeholder(tf.float32, [None, n_dim])\n",
    "W = tf.Variable(tf.zeros([n_dim, n_class]))\n",
    "b = tf.Variable(tf.zeros([n_class]))\n",
    "y_ = tf.placeholder(tf.float32, [None, n_class])\n",
    "\n",
    "#Define the model\n",
    "def multilayer_perceptron(x, weights, biases):\n",
    "    # Hidden layer with RELU activation\n",
    "    \n",
    "    layer_1 = tf.add(tf.matmul(x, weights['h1']), biases['b1'])\n",
    "    layer_1 = tf.nn.sigmoid(layer_1)\n",
    "    \n",
    "    #Hidden layer with sigmoid activation\n",
    "    layer_2 = tf.add(tf.matmul(layer_1, weights['h2']), biases['b2'])\n",
    "    layer_2 = tf.nn.sigmoid(layer_2)\n",
    "    \n",
    "    #Hidden layer with sigmoid activation\n",
    "    layer_3 = tf.add(tf.matmul(layer_2, weights['h3']), biases['b3'])\n",
    "    layer_3 = tf.nn.sigmoid(layer_3)\n",
    "    \n",
    "     #Hidden layer with RELU activation\n",
    "    layer_4 = tf.add(tf.matmul(layer_3, weights['h4']), biases['b4'])\n",
    "    layer_4 = tf.nn.relu(layer_4)\n",
    "    \n",
    "    #Output layer with linear activation\n",
    "    out_layer = tf.matmul(layer_4, weights['out']) + biases['out']\n",
    "    return out_layer\n",
    "\n",
    "#Define the weights and the biases for each of the layer\n",
    "\n",
    "weights = {\n",
    "    \n",
    "    'h1': tf.Variable(tf.truncated_normal([n_dim, n_hidden_1])),\n",
    "    'h2': tf.Variable(tf.truncated_normal([n_hidden_1, n_hidden_2])),\n",
    "    'h3': tf.Variable(tf.truncated_normal([n_hidden_2, n_hidden_3])),\n",
    "    'h4': tf.Variable(tf.truncated_normal([n_hidden_3, n_hidden_4])),\n",
    "    'out': tf.Variable(tf.truncated_normal([n_hidden_4, n_class]))\n",
    "}\n",
    "biases = {\n",
    "    \n",
    "    'b1': tf.Variable(tf.truncated_normal([n_hidden_1])),\n",
    "    'b2': tf.Variable(tf.truncated_normal([n_hidden_2])),\n",
    "    'b3': tf.Variable(tf.truncated_normal([n_hidden_3])),\n",
    "    'b4': tf.Variable(tf.truncated_normal([n_hidden_4])),\n",
    "    'out': tf.Variable(tf.truncated_normal([n_class]))\n",
    "}\n",
    "\n",
    "# Initialize all the variables\n",
    "\n",
    "init = tf.global_variables_initializer()\n",
    "\n",
    "saver = tf.train.Saver()\n",
    "\n",
    "# call your model defined\n",
    "y = multilayer_perceptron(x, weights, biases)\n",
    "\n",
    "#Define the cost function and optimizer\n",
    "cost_function = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=y, labels=y_))\n",
    "training_step = tf.train.GradientDescentOptimizer(learning_rate).minimize(cost_function)\n",
    "\n",
    "sess = tf.Session()\n",
    "sess.run(init)\n",
    "\n",
    "#Calculate the cost and the accuracy for each epoch\n",
    "\n",
    "mse_history = []\n",
    "accuracy_history = []\n",
    "\n",
    "for epoch in range(training_epochs):\n",
    "    sess.run(training_step, feed_dict={x: train_x, y_: train_y})\n",
    "    cost = sess.run(cost_function, feed_dict={x: train_x, y_: train_y})\n",
    "    cost_history = np.append(cost_history, cost)\n",
    "    correct_prediction = tf.equal(tf.argmax(y, 1), tf.argmax(y_, 1))\n",
    "    accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n",
    "    #print(\"Accuracy:\", (sess.run(accuracy, feed_dict={x: test_x, y_: test_y})))\n",
    "    pred_y = sess.run(y, feed_dict={x: test_x})\n",
    "    mse = tf.reduce_mean(tf.square(pred_y - test_y))\n",
    "    mse_ = sess.run(mse)\n",
    "    mse_history.append(mse_)\n",
    "    accuracy = (sess.run(accuracy, feed_dict={x: train_x, y_: train_y}))\n",
    "    accuracy_history.append(accuracy)\n",
    "    \n",
    "    print('epoch :', epoch, '-', 'cost:', cost, \"- MSE:\", mse_, \"-Train Accuracy:\", accuracy)\n",
    "    \n",
    "save_path = saver.save(sess, model_path)\n",
    "print(\"Model saved in file: %s\" % save_path)\n",
    "\n",
    "#plot mse and accuracy graph\n",
    "\n",
    "plt.plot(mse_history, 'r')\n",
    "plt.show()\n",
    "plt.plot(accuracy_history)\n",
    "plt.show()\n",
    "\n",
    "#print the final accuracy\n",
    "\n",
    "correct_prediction = tf.equal(tf.argmax(y, 1), tf.argmax(y_, 1))\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n",
    "print(\"Test Accuracy:\", (sess.run(accuracy, feed_dict={x: test_x, y_: test_y})))\n",
    "\n",
    "#print the final mean square error\n",
    "\n",
    "pred_y = sess.run(y, feed_dict={x: test_x})\n",
    "mse = tf.reduce_mean(tf.square(pred_y - test_y))\n",
    "print(\"MSE: %.4f\" % sess.run(mse))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
